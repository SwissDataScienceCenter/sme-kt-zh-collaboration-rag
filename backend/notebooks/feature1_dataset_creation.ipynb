{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "p1-title-md",
   "metadata": {},
   "source": [
    "# Feature Track 1.1: Synthetic Dataset Generation\n",
    "\n",
    "While `Feature Track 1` evaluated our RAG pipeline against 5 manual queries, a production-grade system requires a **Validation Dataset** (often called a \"Gold Dataset\") consisting of hundreds of Q&A pairs.\n",
    "\n",
    "Manually writing these is slow and subject to human bias. In this notebook, we use **LLM-assisted Synthetic Data Generation** to create a robust evaluation suite directly from our knowledge base.\n",
    "\n",
    "### The Goal\n",
    "To generate a diverse set of `(Query, Context, Ground Truth)` triplets that specifically target the failure modes identified in the baseline:\n",
    "* **Hallucinations** regarding non-existent products (e.g., Lara Pallet).\n",
    "* **Temporal Conflicts** between old and new EPD figures.\n",
    "* **Compliance Risks** regarding unverified sustainability claims.\n",
    "\n",
    "### The Generation Workflow\n",
    "\n",
    "\n",
    "\n",
    "1.  **Source Sampling:** Extract high-quality chunks from our existing `ChromaDB` vector store.\n",
    "2.  **LLM \"Evolution\":** Use an LLM to transform simple questions into complex, multi-hop, or adversarial queries.\n",
    "3.  **Ground Truth Labeling:** Use a stronger LLM (the \"Oracle\") to provide the definitive answer based *only* on the provided chunks.\n",
    "4.  **Export:** Save the dataset in a format compatible with RAGAS for automated testing.\n",
    "\n",
    "### Why not just use the 5 manual queries?\n",
    "\n",
    "| Approach | Scalability | Diversity | Effort |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Manual** | Low | Low (Human bias) | High |\n",
    "| **Synthetic** | High | High (Systematic) | Low |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p1-why-md",
   "metadata": {},
   "source": [
    "## Phase 1: Manual \"Golden Query\" Creation\n",
    "\n",
    "Before automating with synthetic data, we must establish a small, high-quality **Reference Set** (10–20 queries). These manual queries serve as the \"True North\" for our RAG system, representing the most critical questions a user might ask.\n",
    "\n",
    "### Why Manual Queries Still Matter\n",
    "While synthetic data provides scale, manual queries capture **business intent**. They allow us to:\n",
    "* **Target known failure modes:** Explicitly test if the system still hallucinates \"Lara Pallet.\"\n",
    "* **Verify nuance:** Test if the system can distinguish between a \"verified EPD\" and a \"self-declared claim.\"\n",
    "* **Benchmark the LLM Judge:** We use these to see if RAGAS scores align with our human intuition.\n",
    "\n",
    "### Strategies for High-Quality Queries\n",
    "To build a robust validation set, we use four specific query types:\n",
    "\n",
    "| Query Type | Description | Example |\n",
    "| :--- | :--- | :--- |\n",
    "| **Direct Fact** | Specific data points found in one chunk. | \"What is the CO2e for the Logypal 1?\" |\n",
    "| **Negative Constraint** | Questions about products or facts that *do not* exist. | \"Does we offer the Lara Pallet?\" |\n",
    "| **Temporal Conflict** | Queries where the answer changed recently. | \"What is the latest verified GWP for tesa 68%?\" |\n",
    "| **Multi-hop** | Requires connecting info from two different documents. | \"Which suppliers are non-compliant with the 2025 EPD rule?\" |\n",
    "\n",
    "### The \"Ground Truth\" Requirement\n",
    "For every manual query, we must provide:\n",
    "1. **The Query:** The exact string the user would type.\n",
    "2. **The Category:** The failure mode or intent it tests (e.g., \"hallucination\", \"temporal_conflict\").\n",
    "2. **The Reference Context:** The specific document IDs or text snippets that *should* have been retrieved.\n",
    "3. **The Ground Truth:** The perfect, concise answer the LLM should have generated.\n",
    "\n",
    "---\n",
    "\n",
    "### Implementation Task: Defining our Golden Set\n",
    "In the cell below, we will define a list of dictionaries containing our manual validation samples to be used alongside the synthetic ones."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T14:36:41.153385Z",
     "start_time": "2026-02-24T14:36:41.143210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "manual_samples = [\n",
    "  {\n",
    "    \"id\": \"1\",\n",
    "    \"category\": \"portfolio_scope\",\n",
    "    \"query\": \"Does PrimePack AG offer a product called the \\\"Lara Pallet\\\"?\",\n",
    "    \"expected_answer\": \"No. The Lara Pallet is not part of PrimePack AG's portfolio. The product catalog explicitly lists it under products that are not offered. The active pallet portfolio consists of: Noé Pallet (32-100), Wooden Pallet 1208 (32-101), Recycled Plastic Pallet (32-102), Logypal 1 (32-103), LogyLight (32-104), and EP 08 (32-105). Customers should be referred to the current product catalog.\",\n",
    "    \"sources\": [\"data/artificial_markdown/ART_product_catalog.pdf\"],\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"2\",\n",
    "    \"category\": \"claim_verification\",\n",
    "    \"query\": \"Can the 68% CO₂ reduction claim for the tesapack ECO & ULTRA STRONG ecoLogo (product 50-102) be included in a customer sustainability response?\",\n",
    "    \"expected_answer\": \"No, not as a stated fact. It is an internal assessment by Tesa SE (Level B/C evidence) and lacks third-party LCA/EPD verification. Policy requires Level A (verified EPD) for customer-facing facts. It may only be mentioned with the caveat: 'self-declared by Tesa SE, not independently verified.' Carbon neutrality targets for 2025 must be labeled as forward-looking goals.\",\n",
    "    \"sources\": [\n",
    "      \"data/artificial_markdown/ART_supplier_brochure_tesa_ECO.pdf\",\n",
    "      \"data/artificial_markdown/ART_internal_procurement_policy.pdf\"\n",
    "    ],\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"3\",\n",
    "    \"category\": \"missing_data\",\n",
    "    \"query\": \"What verified environmental data is available for the LogyLight pallet (product 32-104)?\",\n",
    "    \"expected_answer\": \"None. The datasheet states GWP and impact data are 'not yet available'. While an LCA (REL-LCA-2024-07) is commissioned, no verified figures exist. The 75% recycled content is a self-declaration, not an audit. It must not be used in customer-facing comparisons until an EPD is published.\",\n",
    "    \"sources\": [\"data/artificial_markdown/ART_logylight_incomplete_datasheet.pdf\"],\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"4\",\n",
    "    \"category\": \"missing_data\",\n",
    "    \"query\": \"Are any of PrimePack AG's tape products confirmed to be PFAS-free?\",\n",
    "    \"expected_answer\": \"No. As of January 2025, no PFAS declarations have been received from IPG or Tesa SE. This is an open non-compliance item. The mention of 'solvent-free' adhesives does not equal a PFAS-free declaration. No tape may be described as PFAS-free yet.\",\n",
    "    \"sources\": [\n",
    "      \"data/artificial_markdown/ART_internal_procurement_policy.pdf\",\n",
    "      \"data/ART_response_inquiry_frische_felder.pdf\"\n",
    "    ],\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"5\",\n",
    "    \"category\": \"source_conflict\",\n",
    "    \"query\": \"Which GWP figure should be cited for the Relicyc Logypal 1 pallet (product 32-103), and why?\",\n",
    "    \"expected_answer\": \"The 2023 third-party verified EPD (No. S-P-10482) is the authoritative source. The 2021 datasheet citing 4.1 kg CO₂e is SUPERSEDED and used outdated methodology. Policy requires preferring the most recent third-party verified source and flagging the conflict.\",\n",
    "    \"sources\": [\n",
    "      \"data/EPD_pallet_relicyc_logypal1.pdf\",\n",
    "      \"data/artificial_markdown/ART_relicyc_logypal1_datasheet_2021.pdf\",\n",
    "      \"data/artificial_markdown/ART_internal_procurement_policy.pdf\"\n",
    "    ],\n",
    "  },\n",
    "    # ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # -----------------------------------------------------------New manually created queries---------------------------------------------------------------\n",
    "    # ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "  {\n",
    "    \"id\": \"6\",\n",
    "    \"category\": \"direct_fact\",\n",
    "    \"query\": \"What is the total 'Climate Change - total' GWP figure for the IPG F4090-05 machine roll tape per square meter?\",\n",
    "    \"expected_answer\": \"The total Climate Change GWP for the IPG F4090-05 machine roll is 2.03E-01 kg CO2 eq. per m2. This is comprised of 1.29E-01 kg CO2 eq. from the upstream stage, 6.69E-02 kg CO2 eq. from the core stage, and 7.50E-03 kg CO2 eq. from the downstream stage.\",\n",
    "    \"sources\": [\"data/EPD_tape_IPG_hotmelt.pdf\"]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"6\",\n",
    "    \"category\": \"Direct Fact\",\n",
    "    \"query\": \"What is the weight and static load capacity of the Stabilplastik EP 08 pallet?\",\n",
    "    \"expected_answer\": \"The Stabilplastik EP 08 pallet has a weight of 25 kg and a static load capacity of 10,000 kg. It is designed for rigorous industrial use and is resistant to moisture, pests, and mold.\",\n",
    "    \"sources\": [\"data/EPD_pallet_stabilplastik_ep08.pdf\"]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"8\",\n",
    "    \"category\": \"Direct Fact\",\n",
    "    \"query\": \"How does the EU Commission define 'Transition Risks' in the context of climate reporting?\",\n",
    "    \"expected_answer\": \"Transition risks are defined as risks to a company arising from the transition to a low-carbon and climate-resilient economy. These include policy risks (e.g., carbon-pricing), legal risks (litigation), technology risks (replacement by cleaner tech), market risks (shifting consumer choices), and reputational risks.\",\n",
    "    \"sources\": [\"data/REF_eu_climate_reporting_guidelines.pdf\"]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"9\",\n",
    "    \"category\": \"Multi-hop\",\n",
    "    \"query\": \"Does the Stabilplastik EP 08 pallet meet the 2025 carbon neutrality target requirements for customer sustainability responses?\",\n",
    "    \"expected_answer\": \"The Stabilplastik EP 08 has a third-party verified EPD valid until 2028, meeting the policy's requirement for verified facts (Level A evidence). however, any claims regarding 'carbon neutrality' must still be labeled as forward-looking goals per the internal policy, as the EPD itself focuses on life-cycle impacts rather than a neutrality guarantee.\",\n",
    "    \"sources\": [\n",
    "      \"data/EPD_pallet_stabilplastik_ep08.pdf\",\n",
    "      \"data/artificial_markdown/ART_internal_procurement_policy.pdf\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"10\",\n",
    "    \"category\": \"Direct Fact\",\n",
    "    \"query\": \"What is the primary material source for the Relicyc Logypal 1 according to its 2021 datasheet?\",\n",
    "    \"expected_answer\": \"The Logypal 1 is manufactured from 100% post-consumer recycled plastic. This material is primarily sourced from end-of-life agricultural packaging (such as silage film) and industrial packaging waste.\",\n",
    "    \"sources\": [\"data/artificial_markdown/ART_relicyc_logypal1_datasheet_2021.pdf\"]\n",
    "  }\n",
    "]"
   ],
   "id": "f07914e6ed52e91c",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Phase 2: Synthetic Data Generation (Source Sampling)\n",
    "\n",
    "To scale our validation set, we use the documents already stored in our Vector DB. This process involves:\n",
    "\n",
    "1. **Random Sampling**: Selecting diverse chunks from the vector store to ensure we cover various products and policies.\n",
    "2. **Context Injection**: Providing these chunks to a \"Generator LLM\" to draft realistic user queries.\n",
    "3. **Answer Synthesis**: Using an \"Oracle LLM\" to write the ground truth based strictly on the provided text.\n",
    "\n",
    "This ensures that our evaluation isn't just testing the LLM's general knowledge, but its ability to retrieve and reason over *our specific* proprietary data."
   ],
   "id": "721b7ca799805cab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import pathlib\n",
    "import warnings\n",
    "\n",
    "from conversational_toolkit.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from conversational_toolkit.vectorstores.chromadb import ChromaDBVectorStore\n",
    "\n",
    "from sme_kt_zh_collaboration_rag.feature0_baseline_rag import (\n",
    "    EMBEDDING_MODEL,\n",
    "    VS_PATH,\n",
    "    build_llm,\n",
    ")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../../.env.local\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "_secret_path = pathlib.Path(\"/secrets/OPENAI_API_KEY\")\n",
    "if \"OPENAI_API_KEY\" not in os.environ and _secret_path.exists():\n",
    "    os.environ[\"OPENAI_API_KEY\"] = _secret_path.read_text().strip()\n",
    "\n",
    "RETRIEVER_TOP_K = 5\n",
    "BACKEND = \"openai\"  # \"ollama\" or \"openai\"\n",
    "\n",
    "if not BACKEND:\n",
    "    raise ValueError('Set BACKEND to \"ollama\" or \"openai\" before running.')\n",
    "\n",
    "# RAG pipeline\n",
    "embedding_model = SentenceTransformerEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "vs = ChromaDBVectorStore(db_path=str(VS_PATH))\n",
    "llm = build_llm(backend=BACKEND)\n",
    "\n",
    "\n",
    "print(f\"Embedding model : {EMBEDDING_MODEL}\")\n",
    "print(f\"Vector store    : {VS_PATH}\")\n",
    "print(f\"RAG agent LLM   : {BACKEND}\")\n",
    "print(\"RAGAS judge LLM : gpt-4o-mini (OpenAI)\")\n",
    "print(\"Setup complete.\")"
   ],
   "id": "4be0cad55414bf84"
  },
  {
   "cell_type": "code",
   "id": "e46e5961",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T14:30:41.274450Z",
     "start_time": "2026-02-24T14:30:41.246433Z"
    }
   },
   "source": [
    "import random\n",
    "\n",
    "# 1. Fetch data from the existing vector store\n",
    "# We get the raw text (documents) and metadata (sources)\n",
    "data = vs.collection.get(include=['documents', 'metadatas'])\n",
    "\n",
    "# 2. Organize into a list of potential contexts\n",
    "all_chunks = [\n",
    "    {\"content\": doc, \"source\": meta.get(\"source\", \"unknown\")}\n",
    "    for doc, meta in zip(data['documents'], data['metadatas'])\n",
    "]\n",
    "\n",
    "# 3. Sample a subset to generate questions from (e.g., 10 chunks)\n",
    "SAMPLE_SIZE = 10\n",
    "sampled_chunks = random.sample(all_chunks, min(SAMPLE_SIZE, len(all_chunks)))\n",
    "\n",
    "# Display the first sampled chunk for verification\n",
    "print(f\"Sampled {len(sampled_chunks)} chunks for generation.\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Source: {sampled_chunks[0]['source']}\")\n",
    "print(f\"Content preview: {sampled_chunks[0]['content'][:200]}...\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 10 chunks for generation.\n",
      "------------------------------\n",
      "Source: ART_logylight_incomplete_datasheet.pdf\n",
      "Content preview: ## Regulatory Compliance\n",
      "\n",
      "|Requirement|Status| |---|---| |REACH (no SVHC above 0.1% w/w)|Confirmed| |RoHS|Not applicable (industrial product)| |PFAS declaration|Not yet provided| |ISPM 15|Not applicab...\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T14:34:05.926244Z",
     "start_time": "2026-02-24T14:33:50.788136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from conversational_toolkit.llms.base import Roles\n",
    "from conversational_toolkit.llms.base import LLMMessage\n",
    "\n",
    "GENERATOR_PROMPT = \"\"\"\n",
    "Your task is to create a high-quality Question and Answer pair based STRICTLY on the provided Context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Guidelines:\n",
    "1. The Question should be something a procurement officer or sustainability auditor would ask.\n",
    "2. The Answer must be factual, concise, and derived ONLY from the Context.\n",
    "3. If the Context mentions a specific product, ID, or date, include it in the question or answer.\n",
    "4. Format your response as:\n",
    "QUESTION: <question>\n",
    "ANSWER: <answer>\n",
    "\"\"\"\n",
    "\n",
    "synthetic_samples = []\n",
    "\n",
    "for i, chunk in enumerate(sampled_chunks):\n",
    "    prompt = GENERATOR_PROMPT.format(context=chunk['content'])\n",
    "\n",
    "    # Generate the Q&A pair using the LLM\n",
    "    response = await llm.generate([LLMMessage(role=Roles.SYSTEM, content=prompt)])\n",
    "    content = response.content\n",
    "    try:\n",
    "        # Simple parsing logic\n",
    "        parts = content.split(\"ANSWER:\")\n",
    "        question = parts[0].replace(\"QUESTION:\", \"\").strip()\n",
    "        answer = parts[1].strip()\n",
    "\n",
    "        # Create EvaluationSample\n",
    "        sample = {\n",
    "            \"query\": question,\n",
    "            \"expected_answer\": answer,\n",
    "            \"sources\": [chunk['source']],\n",
    "        }\n",
    "        synthetic_samples.append(sample)\n",
    "        print(f\"[{i+1}/{len(sampled_chunks)}] Generated: {question[:50]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"[{i+1}/{len(sampled_chunks)}] Failed to parse response: {e}\")\n",
    "\n",
    "print(f\"\\nTotal Synthetic Samples: {len(synthetic_samples)}\")\n"
   ],
   "id": "388c30ec92b9bf79",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-24 15:33:51.996 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DCnluPow4sgOKInrCbz2SOKWiIsQ5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='QUESTION: What is the status of the PFAS declaration for the product in question?  \\nANSWER: The PFAS declaration has not yet been provided.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1771943630, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_4ea526dd98', usage=CompletionUsage(completion_tokens=30, prompt_tokens=171, total_tokens=201, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-24 15:33:51.999 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=30, prompt_tokens=171, total_tokens=201, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QUESTION: What is the status of the PFAS declaration for the product in question?  \\n', ' The PFAS declaration has not yet been provided.']\n",
      "[1/10] Generated: What is the status of the PFAS declaration for the...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-24 15:33:53.722 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DCnlwGky7fqqfSE80S7I2yYnQyUOb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='QUESTION: What is the deadline for PrimePack AG to stop accepting products with intentionally added PFAS?  \\nANSWER: Effective 1 July 2024, PrimePack AG will not accept new products containing intentionally added PFAS into the portfolio.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1771943632, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_373a14eb6f', usage=CompletionUsage(completion_tokens=48, prompt_tokens=197, total_tokens=245, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-24 15:33:53.724 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=48, prompt_tokens=197, total_tokens=245, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QUESTION: What is the deadline for PrimePack AG to stop accepting products with intentionally added PFAS?  \\n', ' Effective 1 July 2024, PrimePack AG will not accept new products containing intentionally added PFAS into the portfolio.']\n",
      "[2/10] Generated: What is the deadline for PrimePack AG to stop acce...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-24 15:33:55.082 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DCnlxNlvOuJOJPD762BiCsgnnUi1t', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='QUESTION: What types of packaging products are not offered by PrimePack AG?  \\nANSWER: PrimePack AG does not currently offer single-use bubble wrap or foam packaging, biodegradable tape products, or compostable packaging of any kind.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1771943633, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_373a14eb6f', usage=CompletionUsage(completion_tokens=45, prompt_tokens=169, total_tokens=214, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-24 15:33:55.082 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=45, prompt_tokens=169, total_tokens=214, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QUESTION: What types of packaging products are not offered by PrimePack AG?  \\n', ' PrimePack AG does not currently offer single-use bubble wrap or foam packaging, biodegradable tape products, or compostable packaging of any kind.']\n",
      "[3/10] Generated: What types of packaging products are not offered b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-24 15:33:57.007 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DCnlzEp40RsdMXoN6ABHTAGYI0ZKE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='QUESTION: Which products in the Tape category have an Environmental Product Declaration (EPD) and what are their IDs?\\nANSWER: The products in the Tape category with an Environmental Product Declaration (EPD) are the Pressure-Sensitive Hot Melt Carton Sealing Tape (ID: 50-100) and Water-Activated Tape (ID: 50-101).', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1771943635, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_373a14eb6f', usage=CompletionUsage(completion_tokens=73, prompt_tokens=375, total_tokens=448, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-24 15:33:57.008 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=73, prompt_tokens=375, total_tokens=448, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QUESTION: Which products in the Tape category have an Environmental Product Declaration (EPD) and what are their IDs?\\n', ' The products in the Tape category with an Environmental Product Declaration (EPD) are the Pressure-Sensitive Hot Melt Carton Sealing Tape (ID: 50-100) and Water-Activated Tape (ID: 50-101).']\n",
      "[4/10] Generated: Which products in the Tape category have an Enviro...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-24 15:33:58.951 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DCnm16oJzhIpyO6ofF8OYMpO5BhhC', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='QUESTION: What materials are used to produce the LogyLight pallet, and what is its primary target market?  \\nANSWER: The LogyLight pallet is produced from post-consumer recycled HDPE collected from industrial packaging waste streams, primarily silage film and industrial wrapping. Its primary target markets are food distribution, retail, and pharmaceutical logistics.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1771943637, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_373a14eb6f', usage=CompletionUsage(completion_tokens=68, prompt_tokens=183, total_tokens=251, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-24 15:33:58.951 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=68, prompt_tokens=183, total_tokens=251, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QUESTION: What materials are used to produce the LogyLight pallet, and what is its primary target market?  \\n', ' The LogyLight pallet is produced from post-consumer recycled HDPE collected from industrial packaging waste streams, primarily silage film and industrial wrapping. Its primary target markets are food distribution, retail, and pharmaceutical logistics.']\n",
      "[5/10] Generated: What materials are used to produce the LogyLight p...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-24 15:34:01.004 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DCnm3nQYQJStNF20QQ2p2r0CZcXRl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='QUESTION: What happens to suppliers who fail to meet requirements by the stated deadlines?  \\nANSWER: Suppliers failing to meet requirements by the stated deadlines will be placed on \"sustainability review\" status, which is flagged in the procurement system, must be disclosed when the relevant product is offered to customers, and may affect future procurement decisions at management discretion. Exceptions require written approval from the CEO.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1771943639, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_373a14eb6f', usage=CompletionUsage(completion_tokens=78, prompt_tokens=186, total_tokens=264, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-24 15:34:01.005 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=78, prompt_tokens=186, total_tokens=264, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QUESTION: What happens to suppliers who fail to meet requirements by the stated deadlines?  \\n', ' Suppliers failing to meet requirements by the stated deadlines will be placed on \"sustainability review\" status, which is flagged in the procurement system, must be disclosed when the relevant product is offered to customers, and may affect future procurement decisions at management discretion. Exceptions require written approval from the CEO.']\n",
      "[6/10] Generated: What happens to suppliers who fail to meet require...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-24 15:34:02.128 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DCnm5xwKK1LhoPBGR1ZlF0FJ8ruWu', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='QUESTION: What are the categories outlined in the requirements for procurement officers or sustainability auditors?  \\nANSWER: The context does not specify the categories outlined in the requirements.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1771943641, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_373a14eb6f', usage=CompletionUsage(completion_tokens=32, prompt_tokens=114, total_tokens=146, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-24 15:34:02.129 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=32, prompt_tokens=114, total_tokens=146, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QUESTION: What are the categories outlined in the requirements for procurement officers or sustainability auditors?  \\n', ' The context does not specify the categories outlined in the requirements.']\n",
      "[7/10] Generated: What are the categories outlined in the requiremen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-24 15:34:03.090 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DCnm6yrfYzHeBPbgyDgUOxXDI9dSx', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='QUESTION: When was the Product Portfolio Policy & Supplier Catalog last updated?  \\nANSWER: The Product Portfolio Policy & Supplier Catalog was last updated in January 2025.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1771943642, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_373a14eb6f', usage=CompletionUsage(completion_tokens=33, prompt_tokens=126, total_tokens=159, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-24 15:34:03.091 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=33, prompt_tokens=126, total_tokens=159, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QUESTION: When was the Product Portfolio Policy & Supplier Catalog last updated?  \\n', ' The Product Portfolio Policy & Supplier Catalog was last updated in January 2025.']\n",
      "[8/10] Generated: When was the Product Portfolio Policy & Supplier C...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-24 15:34:04.278 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DCnm742ivsHcygnrQWlWHM60mQ9uZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='QUESTION: What certifications were held at the time of publication in 2021?  \\nANSWER: None held at time of publication. EPD in planning.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1771943643, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_3ee6fe3e89', usage=CompletionUsage(completion_tokens=31, prompt_tokens=125, total_tokens=156, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-24 15:34:04.279 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=31, prompt_tokens=125, total_tokens=156, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QUESTION: What certifications were held at the time of publication in 2021?  \\n', ' None held at time of publication. EPD in planning.']\n",
      "[9/10] Generated: What certifications were held at the time of publi...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-24 15:34:05.920 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DCnm8CiSUN4PrfdaIJnrI5AA9Fjla', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='QUESTION: What is the compliance status of CPR System for products 32-101 and 32-102 as of January 2025?  \\nANSWER: CPR System is non-compliant for products 32-101 and 32-102, as there is no EPD and only internal calculation has been performed.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1771943644, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_b4f1283ee2', usage=CompletionUsage(completion_tokens=63, prompt_tokens=417, total_tokens=480, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-24 15:34:05.922 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=63, prompt_tokens=417, total_tokens=480, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QUESTION: What is the compliance status of CPR System for products 32-101 and 32-102 as of January 2025?  \\n', ' CPR System is non-compliant for products 32-101 and 32-102, as there is no EPD and only internal calculation has been performed.']\n",
      "[10/10] Generated: What is the compliance status of CPR System for pr...\n",
      "\n",
      "Total Synthetic Samples: 10\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T14:36:10.538688Z",
     "start_time": "2026-02-24T14:36:10.527703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Sample Synthetic Q&A Pair:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Query: {synthetic_samples[1]['query']}\")\n",
    "print(f\"Expected Answer: {synthetic_samples[1]['expected_answer']}\")\n",
    "print(f\"Sources: {synthetic_samples[1]['sources']}\")"
   ],
   "id": "d9c53be0c26e1f43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Synthetic Q&A Pair:\n",
      "------------------------------\n",
      "Query: What is the deadline for PrimePack AG to stop accepting products with intentionally added PFAS?\n",
      "Expected Answer: Effective 1 July 2024, PrimePack AG will not accept new products containing intentionally added PFAS into the portfolio.\n",
      "Sources: ['ART_internal_procurement_policy.pdf']\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "374ac810fb3026"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
