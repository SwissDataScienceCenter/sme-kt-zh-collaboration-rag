{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3-title",
   "metadata": {},
   "source": [
    "# Feature Track 3: Retrieval Strategies\n",
    "\n",
    "---\n",
    "\n",
    "The baseline retriever embeds the user query and finds the nearest chunks by cosine similarity. This works well when the query is well-formed, specific, and aligned with how the data is written. In practice, this assumption often breaks.\n",
    "\n",
    "Retrieval failures are not only about wording, they arise whenever there is a mismatch between user intent, document structure, and retrieval mechanics. Common failure modes include:\n",
    "- Queries that rely on exact identifiers or codes\n",
    "- Queries that mix semantic intent with keyword-level constraints\n",
    "- Queries where many chunks are vaguely relevant, but only a few are actually useful\n",
    "- Queries that should be restricted to a known document or subset, but aren’t\n",
    "\n",
    "One visible manifestation of these failures is vocabulary mismatch:\n",
    "\n",
    "> **Vocabulary mismatch** -> the right chunk exists but ranks too low because the phrasing differs:\n",
    "\n",
    "| User query | Document text | Issue |\n",
    "|---|---|---|\n",
    "| `\"FSC-C147829 certificate\"` | `\"complies with FSC standard C147829\"` | Exact string -> semantic embedding is noisy |\n",
    "| `\"PFAS-free\"` | `\"no intentionally added per- and polyfluoroalkyl substances\"` | Acronym vs. full name |\n",
    "| `\"Is this Blauer Engel certified?\"` | `\"Blauer Engel DE-UZ 14\"` | Equivalent claims, different phrasing |\n",
    "\n",
    "\n",
    "But the underlying issue is broader: single-shot semantic retrieval is a blunt tool. It optimizes for general semantic similarity, not precision, constraints, or intent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec0cf9d",
   "metadata": {},
   "source": [
    "This notebook covers three strategies that address this:\n",
    "\n",
    "| # | Strategy | Approach | Extra cost |\n",
    "|---|---|---|---|\n",
    "| 1 | **Baseline** | Single semantic query | — |\n",
    "| 2 | **BM25** | Keyword retrieval, no embedding | Corpus index at startup |\n",
    "| 3 | **Hybrid** | Semantic + BM25 via Reciprocal Rank Fusion | Corpus index at startup |\n",
    "| 4 | **Metadata filter** | Restrict semantic search to a known document | None |\n",
    "\n",
    "\n",
    "Query-transformation strategies are covered in a seperate notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3-setup-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "**Prerequisites:** `conversational-toolkit` and `backend` must be installed in editable mode.\n",
    "For **OpenAI**, set `OPENAI_API_KEY`. For **Ollama**, start `ollama serve` and pull the model.\n",
    "\n",
    "This notebook reuses the vector store from `feature0_baseline_rag.ipynb`.\n",
    "Run that notebook first if the store does not exist yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3-setup-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 14:14:14.335 | DEBUG    | conversational_toolkit.embeddings.sentence_transformer:__init__:57 - Sentence Transformer embeddings model loaded: sentence-transformers/all-MiniLM-L6-v2 with kwargs: {}\n",
      "2026-02-26 14:14:14.341 | WARNING  | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:196 - Skipping unsupported file type '': .DS_Store\n",
      "2026-02-26 14:14:14.343 | INFO     | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:204 - Chunking 34 files from /Users/pkoerner/Desktop/Kanton_Zurich/sme-kt-zh-collaboration-rag/data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 14:14:14.606 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   ART_internal_procurement_policy.pdf: 12 chunks\n",
      "2026-02-26 14:14:14.804 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   ART_logylight_incomplete_datasheet.pdf: 6 chunks\n",
      "2026-02-26 14:14:14.881 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   ART_product_catalog.pdf: 7 chunks\n",
      "2026-02-26 14:14:14.890 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   ART_product_overview.xlsx: 1 chunks\n",
      "2026-02-26 14:14:14.979 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   ART_relicyc_logypal1_datasheet_2021.pdf: 5 chunks\n",
      "2026-02-26 14:14:14.980 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   ART_response_inquiry_frische_felder.md: 6 chunks\n",
      "2026-02-26 14:14:15.074 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   ART_supplier_brochure_CPR_wood_pallet.pdf: 6 chunks\n",
      "2026-02-26 14:14:15.168 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   ART_supplier_brochure_tesa_ECO.pdf: 8 chunks\n",
      "2026-02-26 14:14:17.115 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   EPD_cardboard_grupak_corrugated.pdf: 35 chunks\n",
      "2026-02-26 14:14:18.180 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   EPD_cardboard_redbox_cartonpallet.pdf: 11 chunks\n",
      "2026-02-26 14:14:19.109 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   EPD_pallet_CPR_noe.pdf: 11 chunks\n",
      "2026-02-26 14:14:20.509 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   EPD_pallet_relicyc_logypal1.pdf: 17 chunks\n",
      "2026-02-26 14:14:22.215 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   EPD_pallet_stabilplastik_ep08.pdf: 2 chunks\n",
      "2026-02-26 14:14:24.212 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   EPD_tape_IPG_hotmelt.pdf: 30 chunks\n",
      "2026-02-26 14:14:26.854 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   EPD_tape_IPG_wateractivated.pdf: 63 chunks\n",
      "2026-02-26 14:14:31.355 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   REF_ch_eu_sustainability_obligations.pdf: 1 chunks\n",
      "2026-02-26 14:14:34.682 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   REF_ecologo_catalogue.pdf: 10 chunks\n",
      "2026-02-26 14:14:37.927 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   REF_eu_climate_reporting_guidelines.pdf: 2 chunks\n",
      "2026-02-26 14:14:44.135 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   REF_eu_csrd.pdf: 1 chunks\n",
      "2026-02-26 14:14:55.330 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   REF_ghg_protocol_corporate_standard.pdf: 1 chunks\n",
      "2026-02-26 14:15:07.509 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   REF_ghg_protocol_corporate_value_chain.pdf: 29 chunks\n",
      "2026-02-26 14:15:17.129 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   REF_ghg_protocol_product_lca.pdf: 32 chunks\n",
      "2026-02-26 14:15:17.223 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   REF_iso14024_conformance_statement.pdf: 1 chunks\n",
      "2026-02-26 14:15:17.421 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   SPEC_pallet_CPR_plastic.pdf: 2 chunks\n",
      "2026-02-26 14:15:17.512 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   SPEC_pallet_CPR_recycled_plastic.pdf: 1 chunks\n",
      "2026-02-26 14:15:17.643 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   SPEC_pallet_CPR_wood.pdf: 2 chunks\n",
      "2026-02-26 14:15:17.956 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   SPEC_pallet_relicyc_1208MR.pdf: 2 chunks\n",
      "2026-02-26 14:15:18.201 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   SPEC_pallet_relicyc_logypal1.pdf: 3 chunks\n",
      "2026-02-26 14:15:18.493 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   SPEC_pallet_stabilplastik_ep08.pdf: 1 chunks\n",
      "2026-02-26 14:15:19.022 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   SPEC_tape_CST_synthetic_rubber.pdf: 16 chunks\n",
      "2026-02-26 14:15:19.218 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   SPEC_tape_WAT_260.pdf: 1 chunks\n",
      "2026-02-26 14:15:19.757 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   SPEC_tape_WAT_central_brand.pdf: 16 chunks\n",
      "2026-02-26 14:15:25.973 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   SPEC_tape_tesa_sustainability_report_2024.pdf: 15 chunks\n",
      "2026-02-26 14:15:26.068 | DEBUG    | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:216 -   SPEC_tape_tesa_tesapack58297.pdf: 11 chunks\n",
      "2026-02-26 14:15:26.068 | INFO     | sme_kt_zh_collaboration_rag.feature0_baseline_rag:load_chunks:220 - Done, 367 chunks total\n",
      "2026-02-26 14:15:26.084 | INFO     | sme_kt_zh_collaboration_rag.feature0_baseline_rag:build_vector_store:260 - Reset vector store collection at /Users/pkoerner/Desktop/Kanton_Zurich/sme-kt-zh-collaboration-rag/backend/data_vs.db\n",
      "2026-02-26 14:15:26.085 | INFO     | sme_kt_zh_collaboration_rag.feature0_baseline_rag:build_vector_store:268 - Embedding 367 chunks with 'sentence-transformers/all-MiniLM-L6-v2' ...\n",
      "2026-02-26 14:15:28.742 | DEBUG    | conversational_toolkit.embeddings.sentence_transformer:get_embeddings:76 - sentence-transformers/all-MiniLM-L6-v2 embeddings size: (367, 384)\n",
      "2026-02-26 14:15:28.744 | INFO     | sme_kt_zh_collaboration_rag.feature0_baseline_rag:build_vector_store:272 - Embedding matrix: shape=(367, 384)  dtype=float32\n",
      "2026-02-26 14:15:28.993 | INFO     | sme_kt_zh_collaboration_rag.feature0_baseline_rag:build_vector_store:275 - Done! Vector store written to /Users/pkoerner/Desktop/Kanton_Zurich/sme-kt-zh-collaboration-rag/backend/data_vs.db\n",
      "2026-02-26 14:15:28.994 | INFO     | sme_kt_zh_collaboration_rag.feature0_baseline_rag:build_llm:135 - LLM backend: OpenAI (gpt-4o-mini)\n",
      "2026-02-26 14:15:29.010 | DEBUG    | conversational_toolkit.llms.openai:__init__:63 - OpenAI LLM loaded: gpt-4o-mini; temperature: 0.3; seed: 42; tools: None; tool_choice: None; response_format: {'type': 'text'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store ready.\n",
      "LLM backend: openai\n"
     ]
    }
   ],
   "source": [
    "from conversational_toolkit.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "\n",
    "from sme_kt_zh_collaboration_rag.feature0_baseline_rag import (\n",
    "    build_llm,\n",
    "    build_vector_store,\n",
    "    load_chunks,\n",
    "    EMBEDDING_MODEL,\n",
    "    VS_PATH,\n",
    "    RETRIEVER_TOP_K,\n",
    ")\n",
    "from sme_kt_zh_collaboration_rag.feature3_advanced_retrieval import (\n",
    "    retrieve_baseline,\n",
    "    retrieve_bm25,\n",
    "    retrieve_hybrid,\n",
    "    compare_retrieval_strategies,\n",
    "    get_corpus_from_vector_store,\n",
    "    print_strategy_comparison,\n",
    ")\n",
    "\n",
    "# Choose your LLM backend (only needed for the final answer cells)\n",
    "BACKEND = \"openai\"  # \"ollama\", \"openai\", or \"qwen\"\n",
    "\n",
    "embedding_model = SentenceTransformerEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "print(f\"Embedding model: {EMBEDDING_MODEL}\")\n",
    "\n",
    "# Load documents from DATA_DIR and split them into chunks.\n",
    "chunks = load_chunks(max_files=None)\n",
    "\n",
    "# Set reset=True to rebuild the store from scratch\n",
    "vector_store = await build_vector_store(\n",
    "    chunks,\n",
    "    embedding_model,\n",
    "    db_path=VS_PATH,\n",
    "    reset=True,\n",
    ")\n",
    "print(\"Vector store ready.\")\n",
    "\n",
    "llm = build_llm(backend=BACKEND)\n",
    "print(f\"LLM backend: {BACKEND}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3-corpus-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Build the BM25 Corpus\n",
    "\n",
    "**BM25** (Best Match 25) is a lexical retrieval algorithm, so it requires access to the raw text of the corpus. Unlike vector search, it cannot query an external index incrementally, the corpus must be tokenized and indexed at startup.\n",
    "\n",
    "ndexing is necessary because BM25 precomputes:\n",
    "- Term frequencies per chunk\n",
    "- Document frequencies across the corpus\n",
    "- Normalization statistics (e.g. average document length)\n",
    "At query time, scoring is fast because these statistics are already available.\n",
    "\n",
    "**Memory note:** the corpus is stored as a list of ChunkRecord objects, containing the chunk text and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3-corpus-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching corpus from vector store for BM25 indexing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 14:17:32.368 | DEBUG    | conversational_toolkit.embeddings.sentence_transformer:get_embeddings:76 - sentence-transformers/all-MiniLM-L6-v2 embeddings size: (1, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus size: 367 chunks\n",
      "\n",
      "Sample chunk titles:\n",
      "  ART_supplier_brochure_tesa_ECO.pdf                    '### Climate performance:'\n",
      "  EPD_cardboard_grupak_corrugated.pdf                   '#### [LCA ][information]'\n",
      "  EPD_cardboard_grupak_corrugated.pdf                   '#### [LCA ][information]'\n",
      "  EPD_cardboard_grupak_corrugated.pdf                   '#### [LCA ][information]'\n",
      "  REF_ghg_protocol_product_lca.pdf                      '# **_T_**'\n"
     ]
    }
   ],
   "source": [
    "print(\"Fetching corpus from vector store for BM25 indexing...\")\n",
    "corpus = await get_corpus_from_vector_store(vector_store, embedding_model, n=500)\n",
    "print(f\"Corpus size: {len(corpus)} chunks\")\n",
    "print(\"\\nSample chunk titles:\")\n",
    "for c in corpus[:5]:\n",
    "    src = c.metadata.get(\"source_file\", \"?\")\n",
    "    print(f\"  {src:<52}  {repr(c.title)[:48]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3-bm25-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## BM25 Retrieval\n",
    "\n",
    "**BM25** (Best Match 25) ranks chunks using exact token matches, weighted by corpus-level statistics. There are no embeddings involved—retrieval is a pure string-based scoring operation.\n",
    "\n",
    "\n",
    "BM25 combines three key ideas:\n",
    "- Term Frequency Saturation: Relevance increases with term frequency, but with diminishing returns. A chunk mentioning “python” 100 times is not 10× more relevant than one mentioning it 10 times.\n",
    "- Document Length Normalization: Longer chunks naturally contain more terms. BM25 corrects for this so long chunks are not unfairly favored.\n",
    "- Inverse Document Frequency (IDF): Rare terms (e.g. identifiers, codes, acronyms) carry more weight than common words.\n",
    "\n",
    "The behavior of BM25 depends on two parameters:\n",
    "- k1 (typically 1.2–2.0): controls term-frequency saturation\n",
    "- b (0–1): controls document-length normalization\n",
    "\n",
    "### When BM25 wins over semantic search\n",
    "BM25 excels when queries depend on exact lexical matches, such as:\n",
    "- Identifiers, codes, or SKUs (\"FSC-C147829\")\n",
    "- Acronyms and abbreviations (\"PFAS\", \"SOC 2\")\n",
    "- Product names, standards, or regulatory labels\n",
    "- Error codes or configuration keys\n",
    "In these cases, semantic embeddings may blur or down-rank the most relevant chunk, while BM25 retrieves it reliably.\n",
    "\n",
    "### When BM25 fails\n",
    "BM25 is **vocabulary-literal**. If two phrases share no tokens, BM25 treats them as unrelated:\n",
    "- \"carbon footprint decrease\"\n",
    "- \"CO₂ reduction\"\n",
    "Semantic search handles this naturally; BM25 does not.\n",
    "BM25 also struggles with:\n",
    "- Paraphrases\n",
    "- Synonyms\n",
    "- Implicit or conceptual queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3-bm25-exact-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 15:00:47.980 | DEBUG    | conversational_toolkit.embeddings.sentence_transformer:get_embeddings:76 - sentence-transformers/all-MiniLM-L6-v2 embeddings size: (1, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact query: 'FSC-C147829 certificate'\n",
      "\n",
      "── BM25 ───────────────────────────────────────────────────────\n",
      "  ✓  score=24.2626  ART_supplier_brochure_CPR_wood_pallet.pdf     '## Material Sourcing'\n",
      "  ✓  score=16.7802  ART_internal_procurement_policy.pdf           '### 3.5 FSC and Other Chain-of-Custody'\n",
      "  ✓  score=14.6716  ART_response_inquiry_frische_felder.md        '## Incoming Customer Email'\n",
      "  ✓  score=13.2907  ART_product_catalog.pdf                       '## Open Action Items (January 2025)'\n",
      "  ·  score=8.7897  EPD_pallet_relicyc_logypal1.pdf               '# CONTENT DECLARATION'\n",
      "\n",
      "── Semantic baseline ───────────────────────────────────────────\n",
      "  ✓  score=0.9273  ART_internal_procurement_policy.pdf           '### 3.5 FSC and Other Chain-of-Custody'\n",
      "  ✓  score=1.0484  ART_product_catalog.pdf                       '## Open Action Items (January 2025)'\n",
      "  ✓  score=1.2262  ART_response_inquiry_frische_felder.md        '### Response to Section 2: Cardboard P'\n",
      "  ·  score=1.2539  ART_supplier_brochure_tesa_ECO.pdf            '### Certifications held:'\n",
      "  ✓  score=1.2621  ART_supplier_brochure_CPR_wood_pallet.pdf     '## Material Sourcing'\n",
      "\n",
      "✓ = chunk contains a relevant keyword; · = no match\n"
     ]
    }
   ],
   "source": [
    "# Query where BM25 excels: exact product code / certification number\n",
    "QUERY = \"FSC-C147829 certificate\"\n",
    "KEYWORDS = [\"FSC\", \"C147829\"]\n",
    "# QUERY = \"Is the carbon neutrality claim for the tape product independently verified?\"\n",
    "# KEYWORDS = [\"CO₂\", \"carbon\", \"tesa\", \"verified\", \"68%\", \"tesapack\"]\n",
    "\n",
    "results_bm25_exact = await retrieve_bm25(QUERY, corpus, top_k=RETRIEVER_TOP_K)\n",
    "results_semantic_exact = await retrieve_baseline(\n",
    "    QUERY, embedding_model, vector_store, top_k=RETRIEVER_TOP_K\n",
    ")\n",
    "\n",
    "print(f\"Exact query: {QUERY!r}\\n\")\n",
    "print(\"── BM25 \" + \"─\" * 55)\n",
    "for chunk in results_bm25_exact.chunks[:10]:\n",
    "    src = chunk.metadata.get(\"source_file\", \"?\")\n",
    "    title = chunk.title or \"(no title)\"\n",
    "    hit = any(kw.lower() in (src + title + chunk.content).lower() for kw in KEYWORDS)\n",
    "    print(\n",
    "        f\"  {'✓' if hit else '·'}  score={chunk.score:.4f}  {src:<44}  {title[:38]!r}\"\n",
    "    )\n",
    "\n",
    "print(\"\\n── Semantic baseline \" + \"─\" * 43)\n",
    "for chunk in results_semantic_exact.chunks[:10]:\n",
    "    src = chunk.metadata.get(\"source_file\", \"?\")\n",
    "    title = chunk.title or \"(no title)\"\n",
    "    hit = any(kw.lower() in (src + title + chunk.content).lower() for kw in KEYWORDS)\n",
    "    print(\n",
    "        f\"  {'✓' if hit else '·'}  score={chunk.score:.4f}  {src:<44}  {title[:38]!r}\"\n",
    "    )\n",
    "print(\"\\n✓ = chunk contains a relevant keyword; · = no match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3-hybrid-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hybrid Retrieval: Semantic + BM25 via Reciprocal Rank Fusion\n",
    "\n",
    "Neither strategy dominates. Hybrid retrieval runs both in parallel and merges\n",
    "their ranked lists using **Reciprocal Rank Fusion (RRF)**:\n",
    "\n",
    "```\n",
    "Semantic retriever ──► ranked list A \n",
    "                                   ├── RRF merge ──► final top-k\n",
    "BM25 retriever     ──► ranked list B\n",
    "```\n",
    "\n",
    "**RRF formula:**\n",
    "\n",
    "$$\\text{RRF}(d) = \\sum_{r \\in \\text{retrievers}} \\frac{1}{k + \\text{rank}_r(d)}$$\n",
    "\n",
    "where $k = 60$ (standard default from the RRF paper). Using *ranks* rather than raw scores means L2 distances and BM25 scores, which are on incomparable scales, never need to be normalised.\n",
    "\n",
    "Key properties:\n",
    "- Chunks appearing in **both** lists get the highest scores\n",
    "- Chunks appearing in **only one** list still get credit\n",
    "- Sub-retrievers run **in parallel** -> latency is bounded by the slower one, not their sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3-hybrid-exact-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 17:25:03.707 | DEBUG    | conversational_toolkit.embeddings.sentence_transformer:get_embeddings:76 - sentence-transformers/all-MiniLM-L6-v2 embeddings size: (1, 384)\n",
      "2026-02-26 17:25:03.788 | INFO     | sme_kt_zh_collaboration_rag.feature3_advanced_retrieval:compare_retrieval_strategies:130 - Comparing retrieval strategies for: 'Are any tape products free of per- and polyfluoroalkyl substances?'\n",
      "2026-02-26 17:25:03.802 | DEBUG    | conversational_toolkit.embeddings.sentence_transformer:get_embeddings:76 - sentence-transformers/all-MiniLM-L6-v2 embeddings size: (1, 384)\n",
      "2026-02-26 17:25:03.918 | DEBUG    | conversational_toolkit.embeddings.sentence_transformer:get_embeddings:76 - sentence-transformers/all-MiniLM-L6-v2 embeddings size: (1, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: 'Are any tape products free of per- and polyfluoroalkyl substances?'\n",
      "\n",
      "\n",
      "Relevant keywords: ['PFAS', 'per-', 'polyfluoroalkyl']\n",
      "\n",
      "Strategy                Top-5 retrieved sources\n",
      "──────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "baseline\n",
      "  ✓  ART_internal_procurement_policy.pdf               '### 3.3 PFAS (Per- and Polyfluoroalkyl'\n",
      "  ·  EPD_tape_IPG_wateractivated.pdf                   '###### **Product**'\n",
      "  ·  EPD_tape_IPG_wateractivated.pdf                   '#### **Product**'\n",
      "  ·  EPD_tape_IPG_wateractivated.pdf                   '###### 17'\n",
      "  ·  EPD_tape_IPG_wateractivated.pdf                   '###### **Packaging**'\n",
      "\n",
      "bm25\n",
      "  ✓  ART_internal_procurement_policy.pdf               '### 3.3 PFAS (Per- and Polyfluoroalkyl'\n",
      "  ✓  ART_response_inquiry_frische_felder.md            '## Incoming Customer Email'\n",
      "  ·  EPD_tape_IPG_wateractivated.pdf                   '###### **Product**'\n",
      "  ·  EPD_tape_IPG_wateractivated.pdf                   '###### 17'\n",
      "  ✓  ART_response_inquiry_frische_felder.md            '### Response to Section 1: Tape Produc'\n",
      "\n",
      "hybrid\n",
      "  ✓  ART_internal_procurement_policy.pdf               '### 3.3 PFAS (Per- and Polyfluoroalkyl'\n",
      "  ·  EPD_tape_IPG_wateractivated.pdf                   '###### **Product**'\n",
      "  ·  EPD_tape_IPG_wateractivated.pdf                   '###### 17'\n",
      "  ✓  ART_response_inquiry_frische_felder.md            '## Incoming Customer Email'\n",
      "  ·  EPD_tape_IPG_wateractivated.pdf                   '#### **Product**'\n"
     ]
    }
   ],
   "source": [
    "# Exact-term query: hybrid should match BM25's strong result\n",
    "QUERY = \"Are any tape products free of per- and polyfluoroalkyl substances?\"\n",
    "KEYWORDS = [\"PFAS\", \"per-\", \"polyfluoroalkyl\"]\n",
    "# QUERY = \"Is the carbon neutrality claim for the tape product independently verified?\"\n",
    "# KEYWORDS = [\"CO₂\", \"carbon\", \"tesa\", \"verified\", \"68%\", \"tesapack\"]\n",
    "\n",
    "results_exact_hybrid = await retrieve_hybrid(\n",
    "    QUERY, embedding_model, vector_store, corpus, top_k=RETRIEVER_TOP_K\n",
    ")\n",
    "\n",
    "print(f\"\\nQuery: {QUERY!r}\\n\")\n",
    "results = await compare_retrieval_strategies(\n",
    "    QUERY, embedding_model, vector_store, corpus, top_k=RETRIEVER_TOP_K\n",
    ")\n",
    "print_strategy_comparison(results, relevant_keywords=KEYWORDS, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "q77pdz32c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────\n",
      "  Strategy: BASELINE\n",
      "────────────────────────────────────────────────────────────────────────\n",
      "Sources used:\n",
      "  ✓  ART_internal_procurement_policy.pdf                 '### 3.3 PFAS (Per- and Polyfluoroa\n",
      "  ·  EPD_tape_IPG_wateractivated.pdf                     '###### **Product**'\n",
      "  ·  EPD_tape_IPG_wateractivated.pdf                     '#### **Product**'\n",
      "  ·  EPD_tape_IPG_wateractivated.pdf                     '###### 17'\n",
      "  ·  EPD_tape_IPG_wateractivated.pdf                     '###### **Packaging**'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 17:34:45.786 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDYbxUq4gg5gMTA44rMuMcN6fFv0R', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='As of now, there is no specific information provided in the excerpts regarding whether any tape products are confirmed to be free of per- and polyfluoroalkyl substances (PFAS). However, it is stated that effective **1 July 2024**, PrimePack AG will not accept new products containing intentionally added PFAS and that all tape and adhesive suppliers must provide an explicit PFAS declaration for each product, either confirming that the product is free of intentionally added PFAS or disclosing any PFAS content with concentration and substance identification (source: 1134b8f1-0cab-479d-bd42-bba8f5ca4dba).\\n\\nTherefore, while the commitment to not accept PFAS-containing products is clear, the current status of specific tape products regarding PFAS content is not detailed in the provided excerpts. Thus, I cannot confirm if any tape products are currently free of PFAS.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772123681, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_3ee6fe3e89', usage=CompletionUsage(completion_tokens=185, prompt_tokens=1265, total_tokens=1450, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 17:34:45.788 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=185, prompt_tokens=1265, total_tokens=1450, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "As of now, there is no specific information provided in the excerpts regarding whether any tape products are confirmed to be free of per- and polyfluoroalkyl substances (PFAS). However, it is stated that effective **1 July 2024**, PrimePack AG will not accept new products containing intentionally added PFAS and that all tape and adhesive suppliers must provide an explicit PFAS declaration for each product, either confirming that the product is free of intentionally added PFAS or disclosing any PFAS content with concentration and substance identification (source: 1134b8f1-0cab-479d-bd42-bba8f5ca4dba).\n",
      "\n",
      "Therefore, while the commitment to not accept PFAS-containing products is clear, the current status of specific tape products regarding PFAS content is not detailed in the provided excerpts. Thus, I cannot confirm if any tape products are currently free of PFAS.\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────\n",
      "  Strategy: BM25\n",
      "────────────────────────────────────────────────────────────────────────\n",
      "Sources used:\n",
      "  ✓  ART_internal_procurement_policy.pdf                 '### 3.3 PFAS (Per- and Polyfluoroa\n",
      "  ✓  ART_response_inquiry_frische_felder.md              '## Incoming Customer Email'\n",
      "  ·  EPD_tape_IPG_wateractivated.pdf                     '###### **Product**'\n",
      "  ·  EPD_tape_IPG_wateractivated.pdf                     '###### 17'\n",
      "  ✓  ART_response_inquiry_frische_felder.md              '### Response to Section 1: Tape Pr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 17:34:50.350 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDYc2ZSwPezJBRZIUpI3tgjxRpT69', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='As of now, PrimePack AG does not have PFAS declarations from its tape suppliers, and therefore cannot confirm whether any of the tape products are free of per- and polyfluoroalkyl substances (PFAS). The company has initiated requests for these declarations and will forward them as they are received, but currently, they cannot confirm PFAS-free status for any tape products (source: c5e88c3f-8a17-4994-8d6e-a657b31d8bda).\\n\\nEffective from July 1, 2024, PrimePack AG will not accept new products containing intentionally added PFAS, and all tape and adhesive suppliers are required to provide explicit PFAS declarations for each product (source: 1134b8f1-0cab-479d-bd42-bba8f5ca4dba).', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772123686, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_3ee6fe3e89', usage=CompletionUsage(completion_tokens=176, prompt_tokens=1489, total_tokens=1665, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 17:34:50.351 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=176, prompt_tokens=1489, total_tokens=1665, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "As of now, PrimePack AG does not have PFAS declarations from its tape suppliers, and therefore cannot confirm whether any of the tape products are free of per- and polyfluoroalkyl substances (PFAS). The company has initiated requests for these declarations and will forward them as they are received, but currently, they cannot confirm PFAS-free status for any tape products (source: c5e88c3f-8a17-4994-8d6e-a657b31d8bda).\n",
      "\n",
      "Effective from July 1, 2024, PrimePack AG will not accept new products containing intentionally added PFAS, and all tape and adhesive suppliers are required to provide explicit PFAS declarations for each product (source: 1134b8f1-0cab-479d-bd42-bba8f5ca4dba).\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────\n",
      "  Strategy: HYBRID\n",
      "────────────────────────────────────────────────────────────────────────\n",
      "Sources used:\n",
      "  ✓  ART_internal_procurement_policy.pdf                 '### 3.3 PFAS (Per- and Polyfluoroa\n",
      "  ·  EPD_tape_IPG_wateractivated.pdf                     '###### **Product**'\n",
      "  ·  EPD_tape_IPG_wateractivated.pdf                     '###### 17'\n",
      "  ✓  ART_response_inquiry_frische_felder.md              '## Incoming Customer Email'\n",
      "  ·  EPD_tape_IPG_wateractivated.pdf                     '#### **Product**'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 17:34:55.343 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDYc6uqHvub3Ncu2BExUXkfHUEUqI', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='As of now, there is no specific information provided in the excerpts regarding whether any tape products from PrimePack AG are free of per- and polyfluoroalkyl substances (PFAS). However, it is stated that effective **1 July 2024**, PrimePack AG will not accept new products containing intentionally added PFAS into their portfolio, and that all tape and adhesive suppliers must provide a PFAS declaration for each product confirming either that the product is free of intentionally added PFAS or that PFAS content is disclosed with concentration and substance identification (source: 1134b8f1-0cab-479d-bd42-bba8f5ca4dba).\\n\\nIf you need specific declarations for particular tape products, such as those mentioned in the customer email (Product IDs: 50-100, 50-101, 50-102), this information is not available in the provided excerpts. Therefore, I cannot confirm if any of those products are free of PFAS.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772123690, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_373a14eb6f', usage=CompletionUsage(completion_tokens=201, prompt_tokens=1354, total_tokens=1555, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 17:34:55.344 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=201, prompt_tokens=1354, total_tokens=1555, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "As of now, there is no specific information provided in the excerpts regarding whether any tape products from PrimePack AG are free of per- and polyfluoroalkyl substances (PFAS). However, it is stated that effective **1 July 2024**, PrimePack AG will not accept new products containing intentionally added PFAS into their portfolio, and that all tape and adhesive suppliers must provide a PFAS declaration for each product confirming either that the product is free of intentionally added PFAS or that PFAS content is disclosed with concentration and substance identification (source: 1134b8f1-0cab-479d-bd42-bba8f5ca4dba).\n",
      "\n",
      "If you need specific declarations for particular tape products, such as those mentioned in the customer email (Product IDs: 50-100, 50-101, 50-102), this information is not available in the provided excerpts. Therefore, I cannot confirm if any of those products are free of PFAS.\n"
     ]
    }
   ],
   "source": [
    "from conversational_toolkit.llms.base import LLMMessage, Roles\n",
    "from conversational_toolkit.utils.retriever import build_query_with_chunks\n",
    "from sme_kt_zh_collaboration_rag.feature0_baseline_rag import SYSTEM_PROMPT\n",
    "\n",
    "\n",
    "async def rag_answer_from_chunks(llm, chunks, query):\n",
    "    \"\"\"Generate a RAG answer from pre-retrieved chunks (no internal retrieval).\"\"\"\n",
    "    prompt = build_query_with_chunks(query, list(chunks))\n",
    "    messages = [\n",
    "        LLMMessage(role=Roles.SYSTEM, content=SYSTEM_PROMPT),\n",
    "        LLMMessage(role=Roles.USER, content=prompt),\n",
    "    ]\n",
    "    return (await llm.generate(messages)).content\n",
    "\n",
    "\n",
    "for strategy in (\"baseline\", \"bm25\", \"hybrid\"):\n",
    "    result = results[strategy]\n",
    "    print(f\"\\n{'─' * 72}\")\n",
    "    print(f\"Strategy: {strategy.upper()}\")\n",
    "    print(f\"{'─' * 72}\")\n",
    "    print(\"Sources used:\")\n",
    "    for chunk in result.chunks:\n",
    "        src = chunk.metadata.get(\"source_file\", \"?\")\n",
    "        hit = any(\n",
    "            kw.lower() in (src + (chunk.title or \"\") + chunk.content).lower()\n",
    "            for kw in KEYWORDS\n",
    "        )\n",
    "        print(f\"  {'✓' if hit else '·'}  {src:<50}  {repr(chunk.title or '')[:35]}\")\n",
    "    answer = await rag_answer_from_chunks(llm, result.chunks, QUERY)\n",
    "    print(f\"\\n{answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3-eval-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Quantitative Answer Quality Evaluation\n",
    "\n",
    "Two reference-free RAGAS metrics — no ground truth or proxy labels needed:\n",
    "\n",
    "| Metric | What it measures | Ground truth? |\n",
    "|--------|------------------|---------------|\n",
    "| **Faithfulness** | Fraction of answer claims directly supported by the retrieved context | No |\n",
    "| **AnswerRelevancy** | Whether the answer addresses the actual question | No |\n",
    "\n",
    "For each query, each strategy retrieves chunks and generates an answer. The RAGAS judge LLM then checks the answer against those chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3-eval-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wc/vr2d5w_x7z783sr5x3959rh80000gn/T/ipykernel_36266/976841001.py:3: DeprecationWarning: Importing Faithfulness from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import Faithfulness\n",
      "  from ragas.metrics import (  # type: ignore[attr-defined]\n",
      "/var/folders/wc/vr2d5w_x7z783sr5x3959rh80000gn/T/ipykernel_36266/976841001.py:3: DeprecationWarning: Importing AnswerRelevancy from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import AnswerRelevancy\n",
      "  from ragas.metrics import (  # type: ignore[attr-defined]\n",
      "/var/folders/wc/vr2d5w_x7z783sr5x3959rh80000gn/T/ipykernel_36266/976841001.py:12: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use llm_factory instead: from openai import OpenAI; from ragas.llms import llm_factory; llm = llm_factory('gpt-4o-mini', client=OpenAI(api_key='...'))\n",
      "  ragas_llm = LangchainLLMWrapper(\n",
      "2026-02-26 18:18:02.675 | INFO     | sme_kt_zh_collaboration_rag.feature3_advanced_retrieval:compare_retrieval_strategies:130 - Comparing retrieval strategies for: 'Does PrimePack AG offer a product called the Lara Pallet?'\n",
      "2026-02-26 18:18:02.938 | DEBUG    | conversational_toolkit.embeddings.sentence_transformer:get_embeddings:76 - sentence-transformers/all-MiniLM-L6-v2 embeddings size: (1, 384)\n",
      "2026-02-26 18:18:03.104 | DEBUG    | conversational_toolkit.embeddings.sentence_transformer:get_embeddings:76 - sentence-transformers/all-MiniLM-L6-v2 embeddings size: (1, 384)\n",
      "2026-02-26 18:18:07.310 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDZHvILdeEYAu3MggAQS2DtY6u31R', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Based on the provided excerpts, there is no mention of a product called the \"Lara Pallet\" being offered by PrimePack AG. The company currently offers three product categories: pallets, cardboard boxes, and tape, but the specific products within these categories are listed in a document called _product_overview.xlsx_, which is not provided here. \\n\\nAdditionally, there is a section that outlines products not currently offered by PrimePack AG, but it does not specifically mention the \"Lara Pallet.\" Therefore, I cannot confirm the existence of this product in PrimePack AG\\'s portfolio.\\n\\nIf you need further details, you may want to consult the _product_overview.xlsx_ document directly.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772126283, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_373a14eb6f', usage=CompletionUsage(completion_tokens=138, prompt_tokens=686, total_tokens=824, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 18:18:07.311 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=138, prompt_tokens=686, total_tokens=824, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "2026-02-26 18:18:09.904 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDZHzHq2OKxRb8AuPEsMtP1Ta0IpP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Based on the provided excerpts, PrimePack AG does not currently offer a product called the Lara Pallet. The excerpt from the document titled \"Products NOT in Our Portfolio\" explicitly states that PrimePack AG does not offer any products from suppliers not listed in their product overview, as well as other specific product types, but it does not mention the Lara Pallet specifically. Therefore, I cannot confirm the existence of the Lara Pallet in PrimePack AG\\'s offerings.\\n\\nIf you have further questions or need additional information, please let me know!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772126287, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_373a14eb6f', usage=CompletionUsage(completion_tokens=107, prompt_tokens=1018, total_tokens=1125, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 18:18:09.905 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=107, prompt_tokens=1018, total_tokens=1125, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "2026-02-26 18:18:12.664 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDZI2ByG55IN18PRZRwL92jWiT0yw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Based on the provided excerpts, PrimePack AG does not offer a product called the Lara Pallet. The excerpts indicate that PrimePack AG currently offers three product categories: pallets, cardboard boxes, and tape, but do not list any specific products under those categories. Additionally, the first excerpt explicitly states that any product not listed in the product overview is not offered by PrimePack AG.\\n\\nTherefore, I do not have information confirming the existence of a Lara Pallet in their product offerings. \\n\\n(Source: Products NOT in Our Portfolio, Portfolio Scope)', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772126290, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_373a14eb6f', usage=CompletionUsage(completion_tokens=108, prompt_tokens=885, total_tokens=993, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 18:18:12.665 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=108, prompt_tokens=885, total_tokens=993, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "2026-02-26 18:18:12.665 | INFO     | sme_kt_zh_collaboration_rag.feature3_advanced_retrieval:compare_retrieval_strategies:130 - Comparing retrieval strategies for: 'Which products in the portfolio have a third-party verified EPD?'\n",
      "2026-02-26 18:18:13.106 | DEBUG    | conversational_toolkit.embeddings.sentence_transformer:get_embeddings:76 - sentence-transformers/all-MiniLM-L6-v2 embeddings size: (1, 384)\n",
      "2026-02-26 18:18:13.211 | DEBUG    | conversational_toolkit.embeddings.sentence_transformer:get_embeddings:76 - sentence-transformers/all-MiniLM-L6-v2 embeddings size: (1, 384)\n",
      "2026-02-26 18:18:15.516 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDZI55bGwoRaAdrBGgaf9ffXjaal4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The excerpts provided do not specify which specific products in the portfolio have a third-party verified Environmental Product Declaration (EPD). They mention the process of third-party verification and the involvement of accredited certification bodies, but they do not list any products associated with these EPDs.\\n\\nIf you need information about specific products with third-party verified EPDs, I do not know based on the provided excerpts.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772126293, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_3ee6fe3e89', usage=CompletionUsage(completion_tokens=79, prompt_tokens=1164, total_tokens=1243, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 18:18:15.517 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=79, prompt_tokens=1164, total_tokens=1243, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "2026-02-26 18:18:20.061 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDZI7T0DlwGhkB5M8VoLenNpd1hzc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The products in the PrimePack AG portfolio that have a third-party verified Environmental Product Declaration (EPD) are:\\n\\n1. **Product 50-100 (IPG Hot Melt Tape)** - EPD available, third-party verified.\\n2. **Product 50-101 (IPG Water-Activated Tape)** - EPD available, third-party verified.\\n3. **Product 11-101 (Grupak corrugated cardboard packaging)** - EPD available, third-party verified.\\n4. **Product 32-100 (CPR System)** - EPD available, third-party verified.\\n5. **Product 32-103 (Relicyc)** - EPD available, third-party verified.\\n6. **Product 32-105 (StabilPlastik)** - EPD available, third-party verified.\\n7. **Product 11-100 (Redbox)** - EPD available, third-party verified.\\n\\nHowever, **Product 50-102 (Tesa tesapack ECO)** does not have an EPD available and its carbon neutrality claims are not independently verified (self-declared) (source: Response to Section 1 and Environmental Data). \\n\\nPlease let me know if you need further information!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772126295, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_373a14eb6f', usage=CompletionUsage(completion_tokens=247, prompt_tokens=1657, total_tokens=1904, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 18:18:20.062 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=247, prompt_tokens=1657, total_tokens=1904, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "2026-02-26 18:18:23.699 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDZICjQvZNLqkSaqjgW8JLxfNtoLV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The products in the PrimePack AG portfolio that have a third-party verified Environmental Product Declaration (EPD) are:\\n\\n1. **Product 50-100**: IPG Hot Melt Tape - EPD available, third-party verified.\\n2. **Product 50-101**: IPG Water-Activated Tape - EPD available, third-party verified.\\n3. **Product 50-102**: Tesa tesapack ECO - No EPD available; the sustainability claims are based on an internal assessment and not independently verified (source: excerpt from the response to Section 1: Tape Products).\\n\\nTherefore, the only products with third-party verified EPDs are the IPG Hot Melt Tape and the IPG Water-Activated Tape (source: excerpt from the response to Section 1: Tape Products).', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772126300, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_373a14eb6f', usage=CompletionUsage(completion_tokens=164, prompt_tokens=1636, total_tokens=1800, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 18:18:23.700 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=164, prompt_tokens=1636, total_tokens=1800, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "2026-02-26 18:18:23.701 | INFO     | sme_kt_zh_collaboration_rag.feature3_advanced_retrieval:compare_retrieval_strategies:130 - Comparing retrieval strategies for: 'Can the 68% CO2 reduction claim for tesapack ECO (product 50-102) be included in a customer sustainability response?'\n",
      "2026-02-26 18:18:23.780 | DEBUG    | conversational_toolkit.embeddings.sentence_transformer:get_embeddings:76 - sentence-transformers/all-MiniLM-L6-v2 embeddings size: (1, 384)\n",
      "2026-02-26 18:18:23.883 | DEBUG    | conversational_toolkit.embeddings.sentence_transformer:get_embeddings:76 - sentence-transformers/all-MiniLM-L6-v2 embeddings size: (1, 384)\n",
      "2026-02-26 18:18:29.131 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDZIGDDXsE2PGh7seNPwIqK9ndcGk', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The 68% CO₂ reduction claim for the tesapack ECO (product 50-102) cannot be included in a customer sustainability response as a verified claim. While tesa\\'s internal comparative assessment indicates a 68% reduction in CO₂ emissions per roll compared to the conventional tesapack baseline product (2019), this claim is based on an internal assessment and has not been independently verified through a third-party Environmental Product Declaration (EPD) or an ISO 14044 lifecycle assessment (source: <source id=\"c5e88c3f-8a17-4994-8d6e-a657b31d8bda\">).\\n\\nFurthermore, any claims regarding carbon neutrality for the tesapack ECO product line must be clearly labeled as targets, not current status, as the goal is to achieve full carbon neutrality by the end of 2025 (source: <source id=\"ffc1f11f-4551-4b22-b6ac-d90665654b9e\">). \\n\\nIn summary, since the CO₂ reduction claim is not independently verified, it should not be included in customer-facing materials.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772126304, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_373a14eb6f', usage=CompletionUsage(completion_tokens=233, prompt_tokens=1245, total_tokens=1478, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 18:18:29.132 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=233, prompt_tokens=1245, total_tokens=1478, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "2026-02-26 18:18:32.287 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDZILjOeQqxMTYK4mhK8kdfjjf7ea', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The 68% CO₂ reduction claim for the tesapack ECO (product 50-102) cannot be included in a customer sustainability response as a verified claim. While Tesa's sustainability brochure references this reduction compared to their 2019 baseline conventional product, it is based on an internal comparative assessment and has not been independently verified through a third-party Environmental Product Declaration (EPD) or an ISO 14044 lifecycle assessment. As such, there is no EPD available for this product at this time (Source: Response to Section 1: Tape Products).\\n\\nTherefore, the claim is a self-declared supplier claim and lacks third-party verification, which is typically required for inclusion in formal sustainability communications.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772126309, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_373a14eb6f', usage=CompletionUsage(completion_tokens=142, prompt_tokens=3089, total_tokens=3231, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 18:18:32.287 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=142, prompt_tokens=3089, total_tokens=3231, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "2026-02-26 18:18:38.037 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDZIOE5vODMYpGfLmJrhkBlk58G9L', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The claim of a 68% CO₂ reduction for the tesapack ECO (product 50-102) can be included in a customer sustainability response, but it is important to note that this claim is based on Tesa's internal comparative assessment and has not been independently verified through a third-party process such as an ISO 14044 lifecycle assessment. Therefore, it is classified as a self-declared supplier claim rather than a verified third-party claim (EPD).\\n\\nSpecifically, the 68% reduction is referenced in Tesa's sustainability brochure and is based on a comparison to their 2019 baseline conventional product. Additionally, Tesa aims for full carbon neutrality for this product by the end of 2025 through various initiatives (source: c5e88c3f-8a17-4994-8d6e-a657b31d8bda, 823aae2a-eddd-4ec4-b612-f2d328f5c9a8, ffc1f11f-4551-4b22-b6ac-d90665654b9a8).\\n\\nIn summary, while you can include the 68% CO₂ reduction claim in your response, it should be clearly stated that it is based on Tesa's internal assessment and not independently verified.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772126312, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_3ee6fe3e89', usage=CompletionUsage(completion_tokens=266, prompt_tokens=1157, total_tokens=1423, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 18:18:38.038 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=266, prompt_tokens=1157, total_tokens=1423, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "2026-02-26 18:18:38.039 | INFO     | sme_kt_zh_collaboration_rag.feature3_advanced_retrieval:compare_retrieval_strategies:130 - Comparing retrieval strategies for: 'What verified environmental data is available for the LogyLight pallet (product 32-104)?'\n",
      "2026-02-26 18:18:38.124 | DEBUG    | conversational_toolkit.embeddings.sentence_transformer:get_embeddings:76 - sentence-transformers/all-MiniLM-L6-v2 embeddings size: (1, 384)\n",
      "2026-02-26 18:18:38.227 | DEBUG    | conversational_toolkit.embeddings.sentence_transformer:get_embeddings:76 - sentence-transformers/all-MiniLM-L6-v2 embeddings size: (1, 384)\n",
      "2026-02-26 18:18:41.984 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDZIUFvEavTmo4BY4Jw4LiHABWGqP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Currently, there is no verified environmental data available for the LogyLight pallet (product 32-104). An Environmental Product Declaration (EPD) is being prepared, and it is expected to be published by Q2 2026. Until then, no verified environmental impact data can be provided for this product (source: Environmental Data).\\n\\nThe LogyLight pallet is produced from post-consumer recycled HDPE, but the specific environmental impact metrics such as Global Warming Potential, Ozone Depletion Potential, and others are not yet available as the lifecycle assessment (LCA) is still in preparation (source: Environmental Data). \\n\\nIf you need further information or updates, please let me know!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772126318, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_373a14eb6f', usage=CompletionUsage(completion_tokens=140, prompt_tokens=1202, total_tokens=1342, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 18:18:41.985 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=140, prompt_tokens=1202, total_tokens=1342, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "2026-02-26 18:18:46.071 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDZIYDD4R04bnXBDiIUn6B3TBkDbK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The LogyLight pallet (product ID 32-104), supplied by Relicyc, currently does not have any verified environmental data available. A full lifecycle assessment (LCA) has been commissioned and is in preparation, but the Environmental Product Declaration (EPD) is expected to be published by Q2 2026. Until the EPD is available, no verified environmental impact data can be provided for this product (source: c90f57a3-5955-415f-b82b-12951bc2a614).\\n\\nAs of now, the only self-declared information available is that the LogyLight pallet is theoretically 100% recyclable at the end of its life, but this claim has not been certified (source: c90f57a3-5955-415f-b82b-12951bc2a614).', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772126322, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_3ee6fe3e89', usage=CompletionUsage(completion_tokens=174, prompt_tokens=1289, total_tokens=1463, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 18:18:46.072 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=174, prompt_tokens=1289, total_tokens=1463, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "2026-02-26 18:18:50.577 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDZIcB2RNApV8v14yI5t7w02KGZ2S', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Currently, there is no verified environmental data available for the LogyLight pallet (product 32-104). The lifecycle assessment (LCA) is still in preparation, and a third-party verified Environmental Product Declaration (EPD) is expected to be published by Q2 2026. Until the EPD is available, no verified environmental impact data can be provided for this product (source: c90f57a3-5955-415f-b82b-12951bc2a614).\\n\\nThe LogyLight pallet is produced from post-consumer recycled HDPE collected from industrial packaging waste streams, but specific environmental impact metrics such as Global Warming Potential, Ozone Depletion Potential, Acidification Potential, and others are not yet available (source: 2aa711e3-beab-4d7e-8ced-65a6abae9349). \\n\\nIn summary, while the LogyLight pallet is designed with sustainability in mind, verified environmental data will not be accessible until the EPD is published.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772126326, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_3ee6fe3e89', usage=CompletionUsage(completion_tokens=210, prompt_tokens=1250, total_tokens=1460, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 18:18:50.578 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=210, prompt_tokens=1250, total_tokens=1460, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "2026-02-26 18:18:50.579 | INFO     | sme_kt_zh_collaboration_rag.feature3_advanced_retrieval:compare_retrieval_strategies:130 - Comparing retrieval strategies for: 'Which GWP source should be used for Relicyc Logypal 1: the 2021 datasheet or the 2023 EPD?'\n",
      "2026-02-26 18:18:50.655 | DEBUG    | conversational_toolkit.embeddings.sentence_transformer:get_embeddings:76 - sentence-transformers/all-MiniLM-L6-v2 embeddings size: (1, 384)\n",
      "2026-02-26 18:18:50.790 | DEBUG    | conversational_toolkit.embeddings.sentence_transformer:get_embeddings:76 - sentence-transformers/all-MiniLM-L6-v2 embeddings size: (1, 384)\n",
      "2026-02-26 18:18:54.998 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDZIhukf7jolY9v8dd6KQSYWq4jcK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='For the Relicyc Logypal 1, you should use the 2023 Environmental Product Declaration (EPD) if it is available. However, based on the excerpts provided, it appears that the EPD for Relicyc LogyLight (which may be related to Logypal 1) is expected to be published by Q2 2026, and there is currently no verified environmental impact data available for this product (source: Environmental Data). \\n\\nThe 2021 datasheet does not provide any Global Warming Potential (GWP) data either, as it states that the data is not yet available and that the Life Cycle Assessment (LCA) is still in preparation (source: Logypal 1 Product Data Sheet).\\n\\nIn summary, since both the 2021 datasheet and the anticipated EPD do not provide GWP data, it is unclear which source should be used for GWP at this time. Therefore, I cannot provide a definitive answer based on the information available.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772126331, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_3ee6fe3e89', usage=CompletionUsage(completion_tokens=204, prompt_tokens=1063, total_tokens=1267, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 18:18:54.999 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=204, prompt_tokens=1063, total_tokens=1267, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "2026-02-26 18:19:09.256 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDZIlUe0dOQfwehEjNGM1OWPj09y4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='To determine which Global Warming Potential (GWP) source should be used for Relicyc Logypal 1, the 2023 Environmental Product Declaration (EPD) should be prioritized over the 2021 datasheet. \\n\\nThe 2023 EPD is a third-party verified document and is likely to provide more accurate and updated information regarding GWP values compared to the self-declared claims in the 2021 datasheet. According to the guidelines, companies should use the most recent GWP values published by the Intergovernmental Panel on Climate Change (IPCC) when calculating their GHG emissions inventory (source: Chapter 11.2, Product Life Cycle Accounting and Reporting Standard).\\n\\nThus, the 2023 EPD is the recommended source for GWP values for Relicyc Logypal 1.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772126335, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_373a14eb6f', usage=CompletionUsage(completion_tokens=167, prompt_tokens=18511, total_tokens=18678, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 18:19:09.257 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=167, prompt_tokens=18511, total_tokens=18678, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "2026-02-26 18:19:17.077 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDZIzFCUcsOQuDyF8Rb1fUl7GiI1X', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='For the Relicyc Logypal 1, you should use the 2023 Environmental Product Declaration (EPD) as the source for Global Warming Potential (GWP) values, assuming it is available and verified. The 2021 datasheet may contain preliminary or self-declared claims, which are not as reliable as third-party verified data.\\n\\nHowever, based on the excerpts provided, it appears that the 2023 EPD is still in preparation and the full lifecycle assessment is not yet completed. The EPD is expected to be published by Q2 2026, and until then, no verified environmental impact data can be provided for this product (source: excerpt from the environmental data section). \\n\\nTherefore, if you need GWP values for immediate use, you may not have a verified source available until the EPD is published. In summary, use the 2023 EPD when it becomes available, but currently, no verified GWP data is available for Relicyc Logypal 1.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772126349, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_373a14eb6f', usage=CompletionUsage(completion_tokens=206, prompt_tokens=8217, total_tokens=8423, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 18:19:17.078 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=206, prompt_tokens=8217, total_tokens=8423, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "2026-02-26 18:19:17.078 | INFO     | sme_kt_zh_collaboration_rag.feature3_advanced_retrieval:compare_retrieval_strategies:130 - Comparing retrieval strategies for: 'Are any tape products confirmed to be PFAS-free?'\n",
      "2026-02-26 18:19:17.222 | DEBUG    | conversational_toolkit.embeddings.sentence_transformer:get_embeddings:76 - sentence-transformers/all-MiniLM-L6-v2 embeddings size: (1, 384)\n",
      "2026-02-26 18:19:17.331 | DEBUG    | conversational_toolkit.embeddings.sentence_transformer:get_embeddings:76 - sentence-transformers/all-MiniLM-L6-v2 embeddings size: (1, 384)\n",
      "2026-02-26 18:19:20.486 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDZJ7OpFJnMHhzbdZROIfRngMa4PF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='As of now, PrimePack AG cannot confirm any tape products to be PFAS-free. The company has initiated requests for PFAS declarations from all tape suppliers, but currently, no declarations have been received. Therefore, they cannot verify the PFAS-free status of any tape products at this time (source: 3.3 PFAS, Response to Section 1: Tape Products).\\n\\nEffective from July 1, 2024, PrimePack AG will require explicit PFAS declarations for all tape and adhesive products, confirming either that the product is free of intentionally added PFAS or that any PFAS content is disclosed (source: 3.3 PFAS). Until these declarations are received, no claims regarding PFAS-free status should be made (source: Customer Communication Rules).', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772126357, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_3ee6fe3e89', usage=CompletionUsage(completion_tokens=156, prompt_tokens=1043, total_tokens=1199, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 18:19:20.487 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=156, prompt_tokens=1043, total_tokens=1199, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "2026-02-26 18:19:25.488 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDZJAq7cWrDtgz82sEwyvmxkgY9AY', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Currently, PrimePack AG does not have confirmed PFAS-free status for any of its tape products. The company has reviewed the technical documentation for its tape products but has not yet received PFAS declarations from its tape suppliers. Formal requests for PFAS declarations have been initiated, and the company will forward these declarations as they are received. Therefore, they cannot confirm whether any tape products are PFAS-free at this time (Source: Response to Section 1: Tape Products).\\n\\nEffective July 1, 2024, PrimePack AG will require explicit PFAS declarations from all tape and adhesive suppliers, confirming either that the product is free of intentionally added PFAS or disclosing any PFAS content with concentration and substance identification (Source: PFAS (Per- and Polyfluoroalkyl Substances)). \\n\\nIn summary, there are no confirmed PFAS-free tape products available at this moment.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772126360, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_373a14eb6f', usage=CompletionUsage(completion_tokens=178, prompt_tokens=1220, total_tokens=1398, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 18:19:25.488 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=178, prompt_tokens=1220, total_tokens=1398, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "2026-02-26 18:19:30.817 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDZJFNnMkfnEBf4lQtsN1UmXqej7d', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Currently, PrimePack AG cannot confirm that any tape products are PFAS-free. The company has reviewed the available technical documentation for its tape products but does not yet hold PFAS declarations from its tape suppliers. Formal requests for PFAS declarations have been initiated, and the company will forward any declarations as they are received (source: c5e88c3f-8a17-4994-8d6e-a657b31d8bda).\\n\\nEffective July 1, 2024, PrimePack AG will require all tape and adhesive suppliers to provide an explicit PFAS declaration for each product, confirming either that the product is free of intentionally added PFAS or that any PFAS content is disclosed (source: 1134b8f1-0cab-479d-bd42-bba8f5ca4dba).\\n\\nAs of now, no PFAS-free claims can be made until the necessary declarations are received (source: 30ed4a83-6604-477f-9283-1cf924bb8018).', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772126365, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_373a14eb6f', usage=CompletionUsage(completion_tokens=216, prompt_tokens=1284, total_tokens=1500, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 18:19:30.818 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=216, prompt_tokens=1284, total_tokens=1500, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "2026-02-26 18:19:30.818 | INFO     | sme_kt_zh_collaboration_rag.feature3_advanced_retrieval:compare_retrieval_strategies:130 - Comparing retrieval strategies for: 'Which suppliers are not yet compliant with the EPD requirement by end of 2025?'\n",
      "2026-02-26 18:19:30.911 | DEBUG    | conversational_toolkit.embeddings.sentence_transformer:get_embeddings:76 - sentence-transformers/all-MiniLM-L6-v2 embeddings size: (1, 384)\n",
      "2026-02-26 18:19:31.021 | DEBUG    | conversational_toolkit.embeddings.sentence_transformer:get_embeddings:76 - sentence-transformers/all-MiniLM-L6-v2 embeddings size: (1, 384)\n",
      "2026-02-26 18:19:35.732 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDZJL6YMx2sWqmlpgz3nNwqERfCeA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='As of January 2025, the suppliers that are not yet compliant with the EPD requirement are:\\n\\n1. **CPR System** for products 32-101 and 32-102 - Non-compliant, no EPD; internal calculation only.\\n2. **Tesa SE** for product 50-102 - Non-compliant, no EPD; carbon claims unverified.\\n\\nAdditionally, **Relicyc** for product 32-104 (LogyLight) is in progress with an LCA commissioned, and an EPD is expected in Q2 2025, but is not yet compliant as of January 2025.\\n\\n(Source: ef76e5f1-9744-4a37-a002-c75c442fd692)', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772126371, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_3ee6fe3e89', usage=CompletionUsage(completion_tokens=155, prompt_tokens=995, total_tokens=1150, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 18:19:35.733 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=155, prompt_tokens=995, total_tokens=1150, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "2026-02-26 18:19:40.762 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDZJP4xXO4bcENo2Bcg5y6okDynyK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='By the end of 2025, the following suppliers are not yet compliant with the Environmental Product Declaration (EPD) requirement:\\n\\n1. **CPR System** for products 32-101 and 32-102: Non-compliant, as they have no EPD and are relying on internal calculations only.\\n2. **Tesa SE** for product 50-102: Non-compliant, as there is no EPD available and their carbon claims are unverified (self-declared).\\n\\nAdditionally, **Relicyc** for product 32-104 (LogyLight) is in progress with an LCA commissioned, but the EPD is expected only by Q2 2026, which means it will not be compliant by the end of 2025 (source: ef76e5f1-9744-4a37-a002-c75c442fd692; c90f57a3-5955-415f-b82b-12951bc2a614).', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772126375, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_373a14eb6f', usage=CompletionUsage(completion_tokens=203, prompt_tokens=3866, total_tokens=4069, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 18:19:40.763 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=203, prompt_tokens=3866, total_tokens=4069, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "2026-02-26 18:19:44.846 | DEBUG    | conversational_toolkit.llms.openai:generate:87 - Completion: ChatCompletion(id='chatcmpl-DDZJU3jiH6SvoR5gwV3MEjIdsldXE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='As of January 2025, the following suppliers are not yet compliant with the EPD requirement by the end of 2025:\\n\\n1. **CPR System** for products 32-101 and 32-102: Non-compliant, no EPD; internal calculation only.\\n2. **Tesa SE** for product 50-102: Non-compliant, no EPD; carbon claims unverified.\\n3. **Relicyc** for product 32-104 (LogyLight): In progress, LCA commissioned; EPD expected Q2 2026 (not compliant by end of 2025).\\n\\nThese suppliers either lack a valid third-party verified EPD or are still in the process of obtaining one (Relicyc) (source: ef76e5f1-9744-4a37-a002-c75c442fd692, c90f57a3-5955-415f-b82b-12951bc2a614).', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1772126380, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_3ee6fe3e89', usage=CompletionUsage(completion_tokens=201, prompt_tokens=1299, total_tokens=1500, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2026-02-26 18:19:44.848 | INFO     | conversational_toolkit.llms.openai:generate:88 - LLM Usage: CompletionUsage(completion_tokens=201, prompt_tokens=1299, total_tokens=1500, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 7 samples × 3 strategies (21 total)\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings as LangChainOpenAIEmbeddings\n",
    "from ragas.llms import LangchainLLMWrapper  # type: ignore[import-untyped]\n",
    "from ragas.metrics import (  # type: ignore[attr-defined]\n",
    "    Faithfulness as RagasFaithfulness,\n",
    "    AnswerRelevancy as RagasAnswerRelevancy,\n",
    ")\n",
    "\n",
    "from conversational_toolkit.evaluation import EvaluationSample\n",
    "from conversational_toolkit.evaluation.adapters import evaluate_with_ragas\n",
    "from sme_kt_zh_collaboration_rag.feature1_evaluation import EVALUATION_QUERIES\n",
    "\n",
    "ragas_llm = LangchainLLMWrapper(\n",
    "    ChatOpenAI(model=\"gpt-4o-mini\", max_completion_tokens=8192)\n",
    ")\n",
    "ragas_embeddings = LangChainOpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "queries = [q[\"query\"] for q in EVALUATION_QUERIES]\n",
    "\n",
    "# For each strategy, retrieve chunks, generate an answer, and build an EvaluationSample.\n",
    "strategy_samples: dict[str, list[EvaluationSample]] = {\n",
    "    s: [] for s in (\"baseline\", \"bm25\", \"hybrid\")\n",
    "}\n",
    "\n",
    "for query in queries:\n",
    "    results_q = await compare_retrieval_strategies(\n",
    "        query, embedding_model, vector_store, corpus, top_k=RETRIEVER_TOP_K\n",
    "    )\n",
    "    for strategy in (\"baseline\", \"bm25\", \"hybrid\"):\n",
    "        chunks = list(results_q[strategy].chunks)\n",
    "        answer = await rag_answer_from_chunks(llm, chunks, query)\n",
    "        strategy_samples[strategy].append(\n",
    "            EvaluationSample(\n",
    "                query=query,\n",
    "                answer=answer,\n",
    "                retrieved_chunks=chunks,\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(f\"Built {len(queries)} samples x 3 strategies ({len(queries) * 3} total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3-eval-results",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating baseline...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32463459af0946c6989e013a617202ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating bm25...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5434e451ed4465e9f8fdf731ed5b877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating hybrid...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3696e7c152ff416cbdd369212c1ebf7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Strategy              faithfulness      answer_relevancy\n",
      "──────────────────────────────────────────────────────────\n",
      "baseline                     0.964                 0.138\n",
      "bm25                         0.825                 0.327\n",
      "hybrid                       0.915                 0.250\n"
     ]
    }
   ],
   "source": [
    "metrics = [\n",
    "    RagasFaithfulness(),  # type: ignore[call-arg]\n",
    "    RagasAnswerRelevancy(strictness=1),  # type: ignore[call-arg]\n",
    "]\n",
    "\n",
    "reports = {}\n",
    "for strategy, samples in strategy_samples.items():\n",
    "    print(f\"Evaluating {strategy}...\")\n",
    "    reports[strategy] = evaluate_with_ragas(\n",
    "        samples=samples,\n",
    "        metrics=metrics,\n",
    "        llm=ragas_llm,\n",
    "        embeddings=ragas_embeddings,\n",
    "    )\n",
    "\n",
    "metric_names = list(next(iter(reports.values())).summary().keys())\n",
    "print(f\"\\n{'Strategy':<12}  \" + \"  \".join(f\"{m:>20}\" for m in metric_names))\n",
    "print(\"─\" * (14 + 22 * len(metric_names)))\n",
    "for strategy, report in reports.items():\n",
    "    print(\n",
    "        f\"{strategy:<12}  \"\n",
    "        + \"  \".join(f\"{s:>20.3f}\" for s in report.summary().values())\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3-summary-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Strategy | Best for | Limitation |\n",
    "|---|---|---|\n",
    "| **Baseline (semantic)** | Vocabulary mismatch, paraphrases | Fails on exact terms, IDs | \n",
    "| **BM25** | Exact terms, product codes, acronyms | Fails on semantic queries | \n",
    "| **Hybrid** | Both — consistent across query types | BM25 corpus must fit in memory | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52168b2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
