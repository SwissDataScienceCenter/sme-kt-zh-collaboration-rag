{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c121a09",
   "metadata": {},
   "source": [
    "# 2.c Embedding\n",
    "\n",
    "In this notebook you will see:\n",
    "- How to embed the chunks\n",
    "- How to save them with their meta data in a VectorStore\n",
    "\n",
    "We will use as a chunker the `docling` and the `SpecificCharChunker` from last notebook.\n",
    "\n",
    "Here, OpenAI default embedding used, however specific embeddings might be relevant in specific situation (specific vocabulary, dialect, images, ...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7b5c48",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "066d4ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sieverin\\SDSC\\Code\\sme-kt-zh-collaboration-rag\\rag_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider using the pymupdf_layout package for a greatly improved page layout analysis.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "from conversational_toolkit.vectorstores.chromadb import ChromaDBVectorStore\n",
    "from conversational_toolkit.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "from utils.specific_chunker import SpecificCharChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2482b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_docs = \"data/docs\"\n",
    "path_to_document = os.path.join(path_to_docs, \"alexnet_paper.pdf\")\n",
    "\n",
    "path_to_db = \"data/db\"\n",
    "path_to_vectorstore = os.path.join(path_to_db, \"example.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b5c045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] 2026-02-26 15:17:20,024 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-26 15:17:20,035 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\sieverin\\SDSC\\Code\\sme-kt-zh-collaboration-rag\\rag_venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-26 15:17:20,035 [RapidOCR] main.py:53: Using C:\\Users\\sieverin\\SDSC\\Code\\sme-kt-zh-collaboration-rag\\rag_venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-26 15:17:20,110 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-26 15:17:20,112 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\sieverin\\SDSC\\Code\\sme-kt-zh-collaboration-rag\\rag_venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-26 15:17:20,112 [RapidOCR] main.py:53: Using C:\\Users\\sieverin\\SDSC\\Code\\sme-kt-zh-collaboration-rag\\rag_venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-26 15:17:20,157 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-26 15:17:20,167 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\sieverin\\SDSC\\Code\\sme-kt-zh-collaboration-rag\\rag_venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-26 15:17:20,167 [RapidOCR] main.py:53: Using C:\\Users\\sieverin\\SDSC\\Code\\sme-kt-zh-collaboration-rag\\rag_venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "doc_converter = DocumentConverter()\n",
    "\n",
    "conv_res = doc_converter.convert(path_to_document)\n",
    "md = conv_res.document.export_to_markdown()\n",
    "\n",
    "# replace \\n per \" \", as often just new lines\n",
    "md = re.sub(r\"(?<!\\n)\\n(?!\\n)\", \" \", md)\n",
    "\n",
    "doc_title_to_document = {\"alexnet_paper.pdf\": md}\n",
    "\n",
    "chunker = SpecificCharChunker()\n",
    "chunks = chunker.make_chunks(\n",
    "    split_characters=[\"\\n\\n\\n\", \"\\n\\n\", \"\\n\"],\n",
    "    document_to_text=doc_title_to_document,\n",
    "    max_number_of_characters=1024,\n",
    ")\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5409fa2a",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "\n",
    "Below, we use a wrapper over our abstract implementation, that converts each text in a float representation.\n",
    "\n",
    "REMINDER: Calling OpenAI for embedding induces some (limited) cost.\n",
    "\n",
    "```python\n",
    "class EmbeddingsModel(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for embeddings models.\n",
    "\n",
    "    Attributes:\n",
    "        model_name (str): The name of the embeddings model.\n",
    "        embedding_size (int): The size of the embedding vector.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    async def get_embeddings(self, texts: Union[str, list[str]]) -> NDArray[np.float64]:\n",
    "        \"\"\"\n",
    "        Retrieves the embedding for the given text.\n",
    "\n",
    "        Args:\n",
    "            texts (list[str]): The input text for which the embedding needs to be retrieved.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The embedding vector for the input text.\n",
    "        \"\"\"\n",
    "        pass\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edc3bd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 15:17:31.595 | DEBUG    | conversational_toolkit.embeddings.openai:__init__:20 - OpenAI embeddings model loaded: text-embedding-3-small\n",
      "2026-02-26 15:17:32.393 | INFO     | conversational_toolkit.embeddings.openai:get_embeddings:38 - OpenAI embeddings shape: (96, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Define the embedding model\n",
    "embedding_model = OpenAIEmbeddings(model_name=\"text-embedding-3-small\")\n",
    "\n",
    "# Compute the embeddings for the chunks\n",
    "embeddings = await embedding_model.get_embeddings([c.content for c in chunks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb38c7d",
   "metadata": {},
   "source": [
    "# Store them\n",
    "\n",
    "Those embeddings have to be saved for further used, this is done in a vector store, which typically looks like:\n",
    "\n",
    "```python\n",
    "class VectorStore(ABC):\n",
    "    @abstractmethod\n",
    "    async def insert_chunks(self, chunks: list[Chunk], embedding: NDArray[np.float64]) -> None:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    async def get_chunks_by_embedding(\n",
    "        self, embedding: NDArray[np.float64], top_k: int, filters: dict[str, Any] | None = None\n",
    "    ) -> list[ChunkMatch]:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    async def get_chunks_by_ids(self, chunk_ids: Union[int, list[int]]) -> list[Chunk]:\n",
    "        pass\n",
    "```\n",
    "\n",
    "We will use our implementation that `ChromaDB`, it will save both the text, it's embedding and the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c782db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = ChromaDBVectorStore(path_to_vectorstore)\n",
    "\n",
    "await vector_store.insert_chunks(chunks=chunks, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07aacd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ids', 'embeddings', 'documents', 'uris', 'included', 'data', 'metadatas']) \n",
      "\n",
      "Our results on ILSVRC-2010 are summarized in Table 1. Our network achieves top-1 and top-5 test set error rates of 37.5% and 17.0% 5 . The best performance achieved during the ILSVRC2010 competition was 47.1% and 28.2% with an approach that averages the predictions produced from six sparse-coding models trained on different features [2], and since then the best published results are 45.7% and 25.7% with an approach that averages the predictions of two classifiers trained on Fisher Vectors (FVs) computed from two types of densely-sampled features [24]. \n",
      "\n",
      "{'mime_type': 'text/markdown', 'doc_title': 'alexnet_paper.pdf', 'title': '67'} \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.01619667, -0.0226672 ,  0.06462389, ..., -0.04083079,\n",
       "       -0.0090411 ,  0.0530936 ], shape=(1024,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the content\n",
    "print(vector_store.collection.get().keys(), \"\\n\")\n",
    "\n",
    "print(vector_store.collection.get()[\"documents\"][62], \"\\n\")\n",
    "\n",
    "print(vector_store.collection.get()[\"metadatas\"][62], \"\\n\")\n",
    "\n",
    "vector_store.collection.get(include=[\"embeddings\"])[\"embeddings\"][62, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fd8b89",
   "metadata": {},
   "source": [
    "-----------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
