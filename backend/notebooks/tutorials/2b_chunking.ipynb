{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57d9a435",
   "metadata": {},
   "source": [
    "# 2.b Chunking\n",
    "\n",
    "In this notebook you will see:\n",
    "- How to chunk documents\n",
    "- How to include metadata in the chunks\n",
    "\n",
    "We will use as document parser `docling_core` and only consider text.\n",
    "\n",
    "Here, simple chunking is considered, but more advanced one exist (based on semantic or LLMs, or hierarchical, specialized for given data format, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c52322e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d0517ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sieverin\\SDSC\\Code\\sme-kt-zh-collaboration-rag\\rag_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider using the pymupdf_layout package for a greatly improved page layout analysis.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "from conversational_toolkit.chunking.base import Chunker, Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e5b8623",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_docs = \"data/docs\"\n",
    "path_to_document = os.path.join(path_to_docs, \"alexnet_paper.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9561c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] 2026-02-26 15:19:13,874 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-26 15:19:13,875 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\sieverin\\SDSC\\Code\\sme-kt-zh-collaboration-rag\\rag_venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-26 15:19:13,882 [RapidOCR] main.py:53: Using C:\\Users\\sieverin\\SDSC\\Code\\sme-kt-zh-collaboration-rag\\rag_venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-26 15:19:13,964 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-26 15:19:13,967 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\sieverin\\SDSC\\Code\\sme-kt-zh-collaboration-rag\\rag_venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-26 15:19:13,967 [RapidOCR] main.py:53: Using C:\\Users\\sieverin\\SDSC\\Code\\sme-kt-zh-collaboration-rag\\rag_venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-26 15:19:14,011 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-26 15:19:14,021 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\sieverin\\SDSC\\Code\\sme-kt-zh-collaboration-rag\\rag_venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-26 15:19:14,021 [RapidOCR] main.py:53: Using C:\\Users\\sieverin\\SDSC\\Code\\sme-kt-zh-collaboration-rag\\rag_venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "doc_converter = DocumentConverter()\n",
    "\n",
    "conv_res = doc_converter.convert(path_to_document)\n",
    "md = conv_res.document.export_to_markdown()\n",
    "\n",
    "# replace \\n per \" \", as often just new lines\n",
    "md = re.sub(r\"(?<!\\n)\\n(?!\\n)\", \" \", md)\n",
    "\n",
    "doc_title_to_document = {\"alexnet_paper.pdf\": md}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2badb3a2",
   "metadata": {},
   "source": [
    "# Chunking\n",
    "\n",
    "A chunk has been defined as a `content` (here, text), a `title`, a `mine_type` and related `metadata`:\n",
    "\n",
    "```python\n",
    "class Chunk(BaseModel):\n",
    "    title: str\n",
    "    content: str\n",
    "    mime_type: str\n",
    "    metadata: dict[str, Any] = Field(default_factory=dict)\n",
    "```\n",
    "\n",
    "A chunker converts an input (i.e. a text), into a list of chunks.`\n",
    "\n",
    "```python\n",
    "class Chunker(ABC):\n",
    "    @abstractmethod\n",
    "    def make_chunks(self, *args: Any, **kwargs: Any) -> list[Chunk]:\n",
    "        pass\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f3395f",
   "metadata": {},
   "source": [
    "## Number of Char Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ed235a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumberOfCharChunker(Chunker):\n",
    "    def make_chunks(\n",
    "        self,\n",
    "        document_to_text: dict[str, str],\n",
    "        max_number_of_characters: int,\n",
    "        chunk_overlap: int,\n",
    "    ) -> list[Chunk]:\n",
    "        \"\"\"Splits the text into chunks of a specified maximum number of characters, with a specified overlap between chunks.\"\"\"\n",
    "\n",
    "        chunk_cnt = 0\n",
    "        chunks: list[Chunk] = []\n",
    "\n",
    "        for doc_title, text in document_to_text.items():\n",
    "            start = 0\n",
    "            end = max_number_of_characters\n",
    "\n",
    "            while start < len(text):\n",
    "                chunk_text = text[start:end]\n",
    "                chunks.append(\n",
    "                    Chunk(\n",
    "                        title=str(chunk_cnt),\n",
    "                        mime_type=\"text/markdown\",\n",
    "                        content=chunk_text,\n",
    "                        metadata={\"start\": start, \"end\": end, \"doc_title\": doc_title},\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                start += max_number_of_characters - chunk_overlap\n",
    "                end += max_number_of_characters - chunk_overlap\n",
    "                chunk_cnt += 1\n",
    "\n",
    "            return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ede7d065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "chunker = NumberOfCharChunker()\n",
    "chunks = chunker.make_chunks(\n",
    "    document_to_text=doc_title_to_document,\n",
    "    max_number_of_characters=1024,\n",
    "    chunk_overlap=128,\n",
    ")\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "636e011f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "text/markdown\n",
      "{'start': 23296, 'end': 24320, 'doc_title': 'alexnet_paper.pdf'} \n",
      "\n",
      "ion error rate stopped improving with the current learning rate. The learning rate was initialized at 0.01 and\n",
      "\n",
      "reduced three times prior to termination. We trained the network for roughly 90 cycles through the training set of 1.2 million images, which took five to six days on two NVIDIA GTX 580 3GB GPUs.\n",
      "\n",
      "## 6 Results\n",
      "\n",
      "Our results on ILSVRC-2010 are summarized in Table 1. Our network achieves top-1 and top-5 test set error rates of 37.5% and 17.0% 5 . The best performance achieved during the ILSVRC2010 competition was 47.1% and 28.2% with an approach that averages the predictions produced from six sparse-coding models trained on different features [2], and since then the best published results are 45.7% and 25.7% with an approach that averages the predictions of two classifiers trained on Fisher Vectors (FVs) computed from two types of densely-sampled features [24].\n",
      "\n",
      "We also entered our model in the ILSVRC-2012 competition and report our results in Table 2. Since the ILSVRC-2012 test set labels are not publi\n"
     ]
    }
   ],
   "source": [
    "print(chunks[26].title)\n",
    "print(chunks[26].mime_type)\n",
    "print(chunks[26].metadata, \"\\n\")\n",
    "print(chunks[26].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78891a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " our model in the ILSVRC-2012 competition and report our results in Table 2. Since the ILSVRC-2012 test set labels are not publicly available, we cannot report test error rates for all the models that we tried. In the remainder of this paragraph, we use va\n"
     ]
    }
   ],
   "source": [
    "# Let's check the overlap\n",
    "print(chunks[27].content[:256])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d69282",
   "metadata": {},
   "source": [
    "## Specific Chars Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb753189",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecificCharChunker(Chunker):\n",
    "    def split_on_character(self, text: str, split_character: str) -> list[str]:\n",
    "        \"\"\"Splits the text on the specified character.\"\"\"\n",
    "        return text.split(split_character)\n",
    "\n",
    "    def split_on_nb_characters(\n",
    "        self, text: str, max_number_of_characters: int\n",
    "    ) -> list[str]:\n",
    "        \"\"\"Splits the text into chunks of a specified maximum number of characters.\"\"\"\n",
    "        return [\n",
    "            text[i : i + max_number_of_characters]\n",
    "            for i in range(0, len(text), max_number_of_characters)\n",
    "        ]\n",
    "\n",
    "    def make_chunks(\n",
    "        self,\n",
    "        split_characters: list[str],\n",
    "        document_to_text: dict[str, str],\n",
    "        max_number_of_characters: int,\n",
    "    ) -> list[Chunk]:\n",
    "        \"\"\"Splits the text into chunks of a specified maximum number of characters, with a specified overlap between chunks.\"\"\"\n",
    "\n",
    "        chunk_cnt = 0\n",
    "\n",
    "        chunks_to_split: list[Chunk] = []\n",
    "        chunks: list[Chunk] = []\n",
    "\n",
    "        chunks_to_split.append(\n",
    "            Chunk(\n",
    "                title=\"0\",\n",
    "                mime_type=\"text/markdown\",\n",
    "                content=document_to_text[\"alexnet_paper.pdf\"],\n",
    "                metadata={\"doc_title\": \"alexnet_paper.pdf\"},\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for split_character in split_characters:\n",
    "            # for each chunk in chunks_to_split, split it using the split_char\n",
    "            # then, if it is too small, remove it from chunks_to_split and add it to chunks\n",
    "            for chunk in chunks_to_split:\n",
    "                split_chunks = self.split_on_character(chunk.content, split_character)\n",
    "\n",
    "                for split_chunk in split_chunks:\n",
    "                    if len(split_chunk) <= max_number_of_characters:\n",
    "                        chunks.append(\n",
    "                            Chunk(\n",
    "                                title=str(chunk_cnt),\n",
    "                                mime_type=\"text/markdown\",\n",
    "                                content=split_chunk,\n",
    "                                metadata={\"doc_title\": chunk.metadata[\"doc_title\"]},\n",
    "                            )\n",
    "                        )\n",
    "                        chunk_cnt += 1\n",
    "                    else:\n",
    "                        chunks_to_split.append(\n",
    "                            Chunk(\n",
    "                                title=str(chunk_cnt),\n",
    "                                mime_type=\"text/markdown\",\n",
    "                                content=split_chunk,\n",
    "                                metadata={\"doc_title\": chunk.metadata[\"doc_title\"]},\n",
    "                            )\n",
    "                        )\n",
    "                        chunk_cnt += 1\n",
    "\n",
    "                # remove the original chunk from chunks_to_split\n",
    "                chunks_to_split.remove(chunk)\n",
    "\n",
    "        # for each chunk still in chunks_to_split, split it using the split_char\n",
    "        # and move them to chunks\n",
    "        for chunk in chunks_to_split:\n",
    "            split_chunks = self.split_on_nb_characters(\n",
    "                chunk.content, max_number_of_characters\n",
    "            )\n",
    "\n",
    "            for split_chunk in split_chunks:\n",
    "                chunks.append(\n",
    "                    Chunk(\n",
    "                        title=str(chunk_cnt),\n",
    "                        mime_type=\"text/markdown\",\n",
    "                        content=split_chunk,\n",
    "                        metadata={\"doc_title\": chunk.metadata[\"doc_title\"]},\n",
    "                    )\n",
    "                )\n",
    "                chunk_cnt += 1\n",
    "\n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea9753ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "chunker = SpecificCharChunker()\n",
    "chunks = chunker.make_chunks(\n",
    "    split_characters=[\"\\n\\n\\n\", \"\\n\\n\", \"\\n\"],\n",
    "    document_to_text=doc_title_to_document,\n",
    "    max_number_of_characters=1024,\n",
    ")\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abb3f8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our results on ILSVRC-2010 are summarized in Table 1. Our network achieves top-1 and top-5 test set error rates of 37.5% and 17.0% 5 . The best performance achieved during the ILSVRC2010 competition was 47.1% and 28.2% with an approach that averages the predictions produced from six sparse-coding models trained on different features [2], and since then the best published results are 45.7% and 25.7% with an approach that averages the predictions of two classifiers trained on Fisher Vectors (FVs) computed from two types of densely-sampled features [24].\\n\\nWe also entered our model in the ILSVRC-2012 competition and report our results in Table 2. Since the ILSVRC-2012 test set labels are not publicly available, we cannot report test error rates for all the models that we tried. In the remainder of this paragraph, we use validation and test error rates interchangeably because in our experience they do not differ by more than 0.1% (see Table 2). The CNN described in this paper achieves a top-5 error rate of 18.2%. Averaging the predictions\\n\\nTable 1: Comparison of results on ILSVRC2010 test set. In italics are best results achieved by others.\\n\\n| Model             | Top-1   | Top-5   | |-------------------|---------|---------| | Sparse coding [2] | 47.1%   | 28.2%   | | SIFT + FVs [24]   | 45.7%   | 25.7%   | | CNN               | 37.5%   | 1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md[23618:24974]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4bf1fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "text/markdown\n",
      "{'doc_title': 'alexnet_paper.pdf'} \n",
      "\n",
      "Our results on ILSVRC-2010 are summarized in Table 1. Our network achieves top-1 and top-5 test set error rates of 37.5% and 17.0% 5 . The best performance achieved during the ILSVRC2010 competition was 47.1% and 28.2% with an approach that averages the predictions produced from six sparse-coding models trained on different features [2], and since then the best published results are 45.7% and 25.7% with an approach that averages the predictions of two classifiers trained on Fisher Vectors (FVs) computed from two types of densely-sampled features [24].\n"
     ]
    }
   ],
   "source": [
    "print(chunks[62].title)\n",
    "print(chunks[62].mime_type)\n",
    "print(chunks[62].metadata, \"\\n\")\n",
    "print(chunks[62].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f7abae",
   "metadata": {},
   "source": [
    "------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
