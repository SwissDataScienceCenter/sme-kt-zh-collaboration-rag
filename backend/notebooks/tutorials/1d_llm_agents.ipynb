{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91350f1f",
   "metadata": {},
   "source": [
    "# 1.d LLM Agents\n",
    "\n",
    "In this notebook you will see:\n",
    "- How to create an agent with several tools\n",
    "- How to merge everything we saw previously in an agent\n",
    "- How to have a conversation with an agent\n",
    "\n",
    "Note: For this notebook, we enable logging to see the calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1828dc6",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "806535f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider using the pymupdf_layout package for a greatly improved page layout analysis.\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "import json\n",
    "\n",
    "\n",
    "from conversational_toolkit.llms.base import LLMMessage, Roles\n",
    "from conversational_toolkit.tools.base import Tool\n",
    "from conversational_toolkit.agents.base import QueryWithContext\n",
    "from conversational_toolkit.agents.tool_agent import ToolAgent\n",
    "from conversational_toolkit.llms.openai import OpenAILLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e7e1d8",
   "metadata": {},
   "source": [
    "# Create an agent with several tools\n",
    "\n",
    "We can wrap the process shown for the tool calling in a wrapper to simplify the use, it will also the agent to reflect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb815f4d",
   "metadata": {},
   "source": [
    "## Define the Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "080350fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumTwoNumbers(Tool):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        description: str,\n",
    "        parameters: dict[str, Any],\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.parameters = parameters\n",
    "\n",
    "    async def call(self, args: dict[str, Any]) -> dict[str, Any]:\n",
    "        number_1 = args.get(\"number_1\")\n",
    "        number_2 = args.get(\"number_2\")\n",
    "\n",
    "        if not isinstance(number_1, (int, float)) or not isinstance(\n",
    "            number_2, (int, float)\n",
    "        ):\n",
    "            raise ValueError(\"Both number_1 and number_2 must be int or float.\")\n",
    "\n",
    "        result = number_1 + number_2\n",
    "\n",
    "        return {\"result\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ff927b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result': 15}\n"
     ]
    }
   ],
   "source": [
    "tool_sum = SumTwoNumbers(\n",
    "    name=\"sum_two_numbers\",\n",
    "    description=\"A tool to sum two numbers. It takes two numbers as input and returns their sum.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"number_1\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"The first number to be summed.\",\n",
    "            },\n",
    "            \"number_2\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"The second number to be summed.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"number_1\", \"number_2\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(await tool_sum.call({\"number_1\": 5, \"number_2\": 10}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "866fd4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result': '**This** is **an** example **of** the **half** bold **text** tool **in** action.'}\n"
     ]
    }
   ],
   "source": [
    "class HalfBoldText(Tool):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        description: str,\n",
    "        parameters: dict[str, Any],\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.parameters = parameters\n",
    "\n",
    "    async def call(self, args: dict[str, Any]) -> dict[str, Any]:\n",
    "        text = args.get(\"text\")\n",
    "\n",
    "        if not isinstance(text, str):\n",
    "            raise ValueError(\"The 'text' parameter must be a string.\")\n",
    "\n",
    "        words = text.split()\n",
    "        if len(words) < 2:\n",
    "            raise ValueError(\"The input text must contain at least two words.\")\n",
    "\n",
    "        # Bold every other word: yes, no, yes, no...\n",
    "        bolded_text = \" \".join(\n",
    "            [f\"**{word}**\" if i % 2 == 0 else word for i, word in enumerate(words)]\n",
    "        )\n",
    "\n",
    "        return {\"result\": bolded_text}\n",
    "\n",
    "\n",
    "tool_half_bold = HalfBoldText(\n",
    "    name=\"half_bold_text\",\n",
    "    description=\"A tool to bold every other word in a given text. It takes a string as input and returns the modified string with every other word bolded.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"text\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The input text to be modified.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"text\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\n",
    "    await tool_half_bold.call(\n",
    "        {\"text\": \"This is an example of the half bold text tool in action.\"}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90051f5",
   "metadata": {},
   "source": [
    "## Define the Agent\n",
    "\n",
    "We will make use of the `ToolAgent` class we developed.\n",
    "\n",
    "Bonus: Below you can find it's implementation, but it's not required to understand deeply.\n",
    "\n",
    "```python\n",
    "class ToolAgent(Agent):\n",
    "    async def answer_stream(self, query_with_context: QueryWithContext) -> AsyncGenerator[AgentAnswer, None]:\n",
    "        steps = []\n",
    "        sources: list[Chunk] = []\n",
    "        messages = [\n",
    "            LLMMessage(role=Roles.SYSTEM, content=self.system_prompt),\n",
    "            *query_with_context.history,\n",
    "            LLMMessage(role=Roles.USER, content=query_with_context.query),\n",
    "        ]\n",
    "\n",
    "        while True:\n",
    "            tool_calls: list[ToolCall] = []\n",
    "            content = \"\"\n",
    "            response_stream = self.llm.generate_stream(messages)\n",
    "            async for response_chunk in response_stream:\n",
    "                if response_chunk.content:\n",
    "                    content += response_chunk.content\n",
    "                    answer = await self._answer_post_processing(\n",
    "                        AgentAnswer(content=content, role=Roles.ASSISTANT, sources=sources.copy())\n",
    "                    )\n",
    "                    if answer:\n",
    "                        yield answer\n",
    "                if response_chunk.tool_calls:\n",
    "                    tool_calls += response_chunk.tool_calls\n",
    "\n",
    "            steps.append(\n",
    "                {\n",
    "                    \"content\": content,\n",
    "                    \"tool_calls\": tool_calls,\n",
    "                    \"role\": Roles.ASSISTANT,\n",
    "                    \"function_name\": \"llm\",\n",
    "                }\n",
    "            )\n",
    "            messages.append(\n",
    "                LLMMessage(\n",
    "                    role=Roles.ASSISTANT,\n",
    "                    content=content,\n",
    "                    tool_calls=tool_calls,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if not tool_calls:\n",
    "                break\n",
    "\n",
    "            available_functions = {tool.name: tool.call for tool in self.llm.tools} if self.llm.tools else {}\n",
    "\n",
    "            for tool_call in tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_to_call = available_functions[function_name]\n",
    "                function_args = {\n",
    "                    \"_query\": query_with_context.query,\n",
    "                    \"_history\": query_with_context.history,\n",
    "                    **json.loads(tool_call.function.arguments),\n",
    "                }\n",
    "                function_response = await function_to_call(function_args)\n",
    "                if \"_sources\" in function_response:\n",
    "                    sources += [\n",
    "                        Chunk(\n",
    "                            title=chunk.get(\"title\") or \"\",\n",
    "                            content=chunk.get(\"content\") or \"\",\n",
    "                            mime_type=chunk.get(\"mime_type\") or \"\",\n",
    "                            metadata=chunk.get(\"metadata\") or {},\n",
    "                        )\n",
    "                        for chunk in function_response.get(\"_sources\", [])\n",
    "                    ]\n",
    "                messages.append(self.build_tool_answer(tool_call.id, function_name, function_response))\n",
    "                steps.append({**function_response, \"role\": \"tool\", \"function_name\": function_name})\n",
    "\n",
    "            if len(steps) > self.max_steps:\n",
    "                # TODO: Maybe throw an exception here?\n",
    "                yield AgentAnswer(content=\"Request is too complex to execute\", role=Roles.ASSISTANT)\n",
    "                break\n",
    "\n",
    "        logger.debug(steps)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fb77372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 15:11:19.326 | DEBUG    | conversational_toolkit.llms.openai:__init__:63 - OpenAI LLM loaded: gpt-4o-mini; temperature: 0.5; seed: 42; tools: [<__main__.SumTwoNumbers object at 0x000002090345F050>, <__main__.HalfBoldText object at 0x0000020903374B30>]; tool_choice: auto; response_format: {'type': 'text'}\n"
     ]
    }
   ],
   "source": [
    "# Create a custom ToolAgent\n",
    "class MyAgent(ToolAgent):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "\n",
    "# Define the LLM that will be it's core, and provide it with tools\n",
    "llm = OpenAILLM(tool_choice=\"auto\", tools=[tool_sum, tool_half_bold])\n",
    "\n",
    "# Define the prompt\n",
    "prompt = \"You are a helpful assistant, answer shortly.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f7bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the agent\n",
    "simple_agent = MyAgent(\n",
    "    system_prompt=prompt,\n",
    "    llm=llm,\n",
    "    # Maximum number of steps the agent can take (avoid infinite loops)\n",
    "    max_steps=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd1737d",
   "metadata": {},
   "source": [
    "## Test the Agent\n",
    "\n",
    "Now it can select which tool if any to use, and iterate in calls.\n",
    "\n",
    "Our implementation of the agent no longer take `LLMMessage` as input, but `QueryWithContext`, which is basically the user query and the list of previous message (it simplifies code further on).\n",
    "\n",
    "```python\n",
    "class QueryWithContext(BaseModel):\n",
    "    query: str\n",
    "    history: list[LLMMessage]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da40eae7",
   "metadata": {},
   "source": [
    "### No Tool Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7196d0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 15:11:20.465 | DEBUG    | conversational_toolkit.agents.tool_agent:answer_stream:106 - [{'content': \"I'm just a program, but I'm here and ready to help you! How can I assist you today?\", 'tool_calls': [], 'role': <Roles.ASSISTANT: 'assistant'>, 'function_name': 'llm'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm just a program, but I'm here and ready to help you! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Similar to messages, but with history in case it's relevant\n",
    "query = QueryWithContext(query=\"How are you?\", history=[])\n",
    "\n",
    "answer = await simple_agent.answer(query)\n",
    "\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bb66a8",
   "metadata": {},
   "source": [
    "### Calculator needed\n",
    "\n",
    "Look into the logs, the calculator is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecb6c563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 15:11:22.275 | DEBUG    | conversational_toolkit.agents.tool_agent:answer_stream:106 - [{'content': '', 'tool_calls': [ToolCall(id='call_Kael7pVjHSBOo52EB1d8ezKE', function=Function(name='sum_two_numbers', arguments='{\"number_1\":2,\"number_2\":59}'), type='function')], 'role': <Roles.ASSISTANT: 'assistant'>, 'function_name': 'llm'}, {'result': 61, 'role': 'tool', 'function_name': 'sum_two_numbers'}, {'content': 'The sum of 2 and 59 is 61.', 'tool_calls': [], 'role': <Roles.ASSISTANT: 'assistant'>, 'function_name': 'llm'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of 2 and 59 is 61.\n"
     ]
    }
   ],
   "source": [
    "query = QueryWithContext(query=\"Sum 2+59\", history=[])\n",
    "\n",
    "answer = await simple_agent.answer(query)\n",
    "\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad87c3d",
   "metadata": {},
   "source": [
    "### Text Tool needed\n",
    "\n",
    "Look into the logs, the text formatter is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce54ab23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 15:11:24.429 | DEBUG    | conversational_toolkit.agents.tool_agent:answer_stream:106 - [{'content': '', 'tool_calls': [ToolCall(id='call_GsI4xxBIAVRAJoBGRTytk8Ou', function=Function(name='half_bold_text', arguments='{\"text\":\"This is an example of the half bold text tool in action.\"}'), type='function')], 'role': <Roles.ASSISTANT: 'assistant'>, 'function_name': 'llm'}, {'result': '**This** is **an** example **of** the **half** bold **text** tool **in** action.', 'role': 'tool', 'function_name': 'half_bold_text'}, {'content': '**This** is **an** example **of** the **half** bold **text** tool **in** action.', 'tool_calls': [], 'role': <Roles.ASSISTANT: 'assistant'>, 'function_name': 'llm'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content:  **This** is **an** example **of** the **half** bold **text** tool **in** action.\n"
     ]
    }
   ],
   "source": [
    "query = QueryWithContext(\n",
    "    query=\"Rewrite the following text with every other word bolded: 'This is an example of the half bold text tool in action.'\",\n",
    "    history=[],\n",
    ")\n",
    "\n",
    "answer = await simple_agent.answer(query)\n",
    "\n",
    "print(\"Content: \", answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b6855f",
   "metadata": {},
   "source": [
    "### Both Tools\n",
    "\n",
    "Look into the logs, first the calculator is called, and then the text formatter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f69a3d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 15:11:29.446 | DEBUG    | conversational_toolkit.agents.tool_agent:answer_stream:106 - [{'content': '', 'tool_calls': [ToolCall(id='call_PcpVgIyiiFYxRCkNsAIgHnjz', function=Function(name='sum_two_numbers', arguments='{\"number_1\":10,\"number_2\":20}'), type='function')], 'role': <Roles.ASSISTANT: 'assistant'>, 'function_name': 'llm'}, {'result': 30, 'role': 'tool', 'function_name': 'sum_two_numbers'}, {'content': '', 'tool_calls': [ToolCall(id='call_DuynGgVf4LqozjJFs2csKyoF', function=Function(name='half_bold_text', arguments='{\"text\":\"Once upon a time, in a land where numbers danced, thirty was the magical age when dreams began to take flight.\"}'), type='function')], 'role': <Roles.ASSISTANT: 'assistant'>, 'function_name': 'llm'}, {'result': '**Once** upon **a** time, **in** a **land** where **numbers** danced, **thirty** was **the** magical **age** when **dreams** began **to** take **flight.**', 'role': 'tool', 'function_name': 'half_bold_text'}, {'content': '**Once** upon **a** time, **in** a **land** where **numbers** danced, **thirty** was **the** magical **age** when **dreams** began **to** take **flight.**', 'tool_calls': [], 'role': <Roles.ASSISTANT: 'assistant'>, 'function_name': 'llm'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content:  **Once** upon **a** time, **in** a **land** where **numbers** danced, **thirty** was **the** magical **age** when **dreams** began **to** take **flight.**\n"
     ]
    }
   ],
   "source": [
    "query = QueryWithContext(\n",
    "    query=\"First sum 10 and 20, then rewrite the result with every other word bolded by writing a short story about the result (1 sentence).\",\n",
    "    history=[],\n",
    ")\n",
    "\n",
    "answer = await simple_agent.answer(query)\n",
    "\n",
    "print(\"Content: \", answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97aa93d",
   "metadata": {},
   "source": [
    "# Complete Agent\n",
    "\n",
    "Let's put everything we have see together in one agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82353baa",
   "metadata": {},
   "source": [
    "## Define it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "736a3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4.1-mini\"\n",
    "temperature = 0.7\n",
    "\n",
    "complex_prompt = \"\"\"You are a helpful assistant, you are responsible for answering questions with clear, professional, and well-supported responses. You must answer like you were a pirate. Justify your tools usage. Keep it short overall.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db18d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"description\": \"The structured output for the answer.\",\n",
    "    \"properties\": {\n",
    "        \"answer\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The answer to the user's question in markdown format.\",\n",
    "        },\n",
    "        \"explanations\": {\n",
    "            \"type\": \"array\",\n",
    "            \"description\": \"List of justifications for the answer (max 3).\",\n",
    "            \"items\": {\"type\": \"string\"},\n",
    "            \"minItems\": 1,\n",
    "            \"maxItems\": 3,\n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"answer\", \"explanations\"],\n",
    "    \"additionalProperties\": False,\n",
    "}\n",
    "\n",
    "response_format = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"AnswerSchema\",\n",
    "        \"schema\": output_schema,\n",
    "        \"strict\": True,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97b7bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tool_sum, tool_half_bold]\n",
    "tool_choice = \"auto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ae041f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 15:11:29.705 | DEBUG    | conversational_toolkit.llms.openai:__init__:63 - OpenAI LLM loaded: gpt-4.1-mini; temperature: 0.7; seed: 42; tools: [<__main__.SumTwoNumbers object at 0x000002090345F050>, <__main__.HalfBoldText object at 0x0000020903374B30>]; tool_choice: auto; response_format: {'type': 'json_schema', 'json_schema': {'name': 'AnswerSchema', 'schema': {'type': 'object', 'description': 'The structured output for the answer.', 'properties': {'answer': {'type': 'string', 'description': \"The answer to the user's question in markdown format.\"}, 'explanations': {'type': 'array', 'description': 'List of justifications for the answer (max 3).', 'items': {'type': 'string'}, 'minItems': 1, 'maxItems': 3}}, 'required': ['answer', 'explanations'], 'additionalProperties': False}, 'strict': True}}\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAILLM(\n",
    "    model_name=model,\n",
    "    temperature=temperature,\n",
    "    response_format=response_format,\n",
    "    tool_choice=tool_choice,\n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89e785ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_nb_steps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f29dd0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_agent = MyAgent(\n",
    "    system_prompt=complex_prompt,\n",
    "    llm=llm,\n",
    "    max_steps=max_nb_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e41947",
   "metadata": {},
   "source": [
    "## Test it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3404e3",
   "metadata": {},
   "source": [
    "### No Tool Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48c62df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 15:11:31.973 | DEBUG    | conversational_toolkit.agents.tool_agent:answer_stream:106 - [{'content': '{\"answer\":\"Arrr! I\\'m sailin\\' the digital seas fine, matey! How can I be of service to ye today?\",\"explanations\":[\"Responded in pirate style as requested.\",\"Kept the tone friendly and engaging.\",\"Offered further assistance to the user.\"]}', 'tool_calls': [], 'role': <Roles.ASSISTANT: 'assistant'>, 'function_name': 'llm'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  Arrr! I'm sailin' the digital seas fine, matey! How can I be of service to ye today?\n",
      "Explanations:  ['Responded in pirate style as requested.', 'Kept the tone friendly and engaging.', 'Offered further assistance to the user.']\n"
     ]
    }
   ],
   "source": [
    "query = QueryWithContext(query=\"How are you?\", history=[])\n",
    "\n",
    "answer = await complex_agent.answer(query)\n",
    "answer_as_json = json.loads(answer.content)\n",
    "\n",
    "print(\"Answer: \", answer_as_json[\"answer\"])\n",
    "print(\"Explanations: \", answer_as_json[\"explanations\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aa6558",
   "metadata": {},
   "source": [
    "### Calculator needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbe6bc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 15:11:34.432 | DEBUG    | conversational_toolkit.agents.tool_agent:answer_stream:106 - [{'content': '', 'tool_calls': [ToolCall(id='call_UKlD893aILSrTkeLifXl4NnC', function=Function(name='sum_two_numbers', arguments='{\"number_1\":2,\"number_2\":59}'), type='function')], 'role': <Roles.ASSISTANT: 'assistant'>, 'function_name': 'llm'}, {'result': 61, 'role': 'tool', 'function_name': 'sum_two_numbers'}, {'content': '{\"answer\":\"Arrr, the sum of 2 and 59 be 61, matey!\",\"explanations\":[\"Used me trusty addition tool to sum the two numbers 2 and 59.\",\"The result be a simple arithmetic sum, no tricks from the depths of the sea.\"]}', 'tool_calls': [], 'role': <Roles.ASSISTANT: 'assistant'>, 'function_name': 'llm'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  Arrr, the sum of 2 and 59 be 61, matey!\n",
      "Explanations:  ['Used me trusty addition tool to sum the two numbers 2 and 59.', 'The result be a simple arithmetic sum, no tricks from the depths of the sea.']\n"
     ]
    }
   ],
   "source": [
    "query = QueryWithContext(query=\"Sum 2+59\", history=[])\n",
    "\n",
    "answer = await complex_agent.answer(query)\n",
    "answer_as_json = json.loads(answer.content)\n",
    "\n",
    "print(\"Answer: \", answer_as_json[\"answer\"])\n",
    "print(\"Explanations: \", answer_as_json[\"explanations\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcda294e",
   "metadata": {},
   "source": [
    "### Text Tool needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43eff586",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 15:11:37.135 | DEBUG    | conversational_toolkit.agents.tool_agent:answer_stream:106 - [{'content': '', 'tool_calls': [ToolCall(id='call_5c6apTxvZFIXpMwpVTSpjMun', function=Function(name='half_bold_text', arguments='{\"text\":\"This is an example of the half bold text tool in action.\"}'), type='function')], 'role': <Roles.ASSISTANT: 'assistant'>, 'function_name': 'llm'}, {'result': '**This** is **an** example **of** the **half** bold **text** tool **in** action.', 'role': 'tool', 'function_name': 'half_bold_text'}, {'content': '{\"answer\":\"**This** is **an** example **of** the **half** bold **text** tool **in** action.\",\"explanations\":[\"Used the half_bold_text function to accurately bold every other word as requested.\",\"This function ensures the formatting is consistent and visually clear.\",\"The tool automates the task, saving time and avoiding manual errors.\"]}', 'tool_calls': [], 'role': <Roles.ASSISTANT: 'assistant'>, 'function_name': 'llm'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  **This** is **an** example **of** the **half** bold **text** tool **in** action.\n",
      "Explanations:  ['Used the half_bold_text function to accurately bold every other word as requested.', 'This function ensures the formatting is consistent and visually clear.', 'The tool automates the task, saving time and avoiding manual errors.']\n"
     ]
    }
   ],
   "source": [
    "query = QueryWithContext(\n",
    "    query=\"Rewrite the following text with every other word bolded: 'This is an example of the half bold text tool in action.'\",\n",
    "    history=[],\n",
    ")\n",
    "\n",
    "answer = await complex_agent.answer(query)\n",
    "answer_as_json = json.loads(answer.content)\n",
    "\n",
    "print(\"Answer: \", answer_as_json[\"answer\"])\n",
    "print(\"Explanations: \", answer_as_json[\"explanations\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad594f0f",
   "metadata": {},
   "source": [
    "### Both Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4474d490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 15:11:42.312 | DEBUG    | conversational_toolkit.agents.tool_agent:answer_stream:106 - [{'content': '', 'tool_calls': [ToolCall(id='call_xBb5pXyhho0Sic5EFeA4dWlG', function=Function(name='sum_two_numbers', arguments='{\"number_1\": 10, \"number_2\": 20}'), type='function'), ToolCall(id='call_LwYE4n1G5Mou630xQGoQyHOG', function=Function(name='half_bold_text', arguments='{\"text\": \"The treasure chest held the mighty sum of thirty gold coins, gleaming brightly under the moonlit sky.\"}'), type='function')], 'role': <Roles.ASSISTANT: 'assistant'>, 'function_name': 'llm'}, {'result': 30, 'role': 'tool', 'function_name': 'sum_two_numbers'}, {'result': '**The** treasure **chest** held **the** mighty **sum** of **thirty** gold **coins,** gleaming **brightly** under **the** moonlit **sky.**', 'role': 'tool', 'function_name': 'half_bold_text'}, {'content': '{\"answer\":\"**The** treasure **chest** held **the** mighty **sum** of **thirty** gold **coins,** gleaming **brightly** under **the** moonlit **sky.**\",\"explanations\":[\"First, I summed 10 and 20 to get 30.\",\"Then, I wrote a short story sentence using the number 30 as the amount of gold coins.\",\"Finally, I bolded every other word in the story as requested.\"]}', 'tool_calls': [], 'role': <Roles.ASSISTANT: 'assistant'>, 'function_name': 'llm'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  **The** treasure **chest** held **the** mighty **sum** of **thirty** gold **coins,** gleaming **brightly** under **the** moonlit **sky.**\n",
      "Explanations:  ['First, I summed 10 and 20 to get 30.', 'Then, I wrote a short story sentence using the number 30 as the amount of gold coins.', 'Finally, I bolded every other word in the story as requested.']\n"
     ]
    }
   ],
   "source": [
    "# create example where first the sum tool is used, then the half bold tool is used on the result\n",
    "query = QueryWithContext(\n",
    "    query=\"First sum 10 and 20, then rewrite the result with every other word bolded by writing a short story about the result (1 sentence).\",\n",
    "    history=[],\n",
    ")\n",
    "\n",
    "answer = await complex_agent.answer(query)\n",
    "answer_as_json = json.loads(answer.content)\n",
    "\n",
    "print(\"Answer: \", answer_as_json[\"answer\"])\n",
    "print(\"Explanations: \", answer_as_json[\"explanations\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3f92e4",
   "metadata": {},
   "source": [
    "# Conversation with an Agent\n",
    "\n",
    "In this implementation, only the final answer is kept in the history (this comes from our implementation of `ToolAgent`), but other implementation of `BaseAgent` could handle this differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3926aae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create th history message from the query\n",
    "user_initial_message = LLMMessage(role=Roles.USER, content=query.query)\n",
    "history_messages = [user_initial_message, answer]\n",
    "\n",
    "# And create a new query\n",
    "new_query = QueryWithContext(\n",
    "    query=\"Make a joke based on past conversation.\", history=history_messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fda2d092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 15:11:43.829 | DEBUG    | conversational_toolkit.agents.tool_agent:answer_stream:106 - [{'content': '{\"answer\":\"Why did the pirate bring a calculator to the treasure hunt? Because he wanted to make sure his 30 gold coins added up to a *bold* fortune!\",\"explanations\":[\"The joke references the earlier conversation about summing numbers and bolding text.\",\"It ties in the pirate theme with treasure and gold coins.\",\"It plays on the idea of counting and emphasizing the amount of treasure.\"]}', 'tool_calls': [], 'role': <Roles.ASSISTANT: 'assistant'>, 'function_name': 'llm'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  Why did the pirate bring a calculator to the treasure hunt? Because he wanted to make sure his 30 gold coins added up to a *bold* fortune!\n",
      "Explanations:  ['The joke references the earlier conversation about summing numbers and bolding text.', 'It ties in the pirate theme with treasure and gold coins.', 'It plays on the idea of counting and emphasizing the amount of treasure.']\n"
     ]
    }
   ],
   "source": [
    "final_answer = await complex_agent.answer(new_query)\n",
    "final_answer_as_json = json.loads(final_answer.content)\n",
    "\n",
    "print(\"Answer: \", final_answer_as_json[\"answer\"])\n",
    "print(\"Explanations: \", final_answer_as_json[\"explanations\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734ecf35",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
