{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91350f1f",
   "metadata": {},
   "source": [
    "# 1.a LLM Introduction\n",
    "\n",
    "In this notebook you will see:\n",
    "- How to call an LLM\n",
    "- How to have a conversation with an LLM\n",
    "- How to add a prompt to an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1828dc6",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "806535f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "from conversational_toolkit.llms.base import LLMMessage, Roles\n",
    "from conversational_toolkit.llms.openai import OpenAILLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f1aeef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"ERROR\", filter=lambda record: record[\"level\"].no < 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d377d34a",
   "metadata": {},
   "source": [
    "# Call an LLM\n",
    "\n",
    "To call an LLM, we have to send a message in a format that provides at least the *content* (for example, the question) and the *role* (who is talking, for example the user). The LLM will answer also with a content and a role (who answered, typically the assistant).\n",
    "\n",
    "```python\n",
    "class Roles(StrEnum):\n",
    "    SYSTEM = \"system\"\n",
    "    USER = \"user\"\n",
    "    ASSISTANT = \"assistant\"\n",
    "    TOOL = \"tool\"\n",
    "    DEVELOPER = \"developer\"\n",
    "\n",
    "class LLMMessage(BaseModel):\n",
    "    content: str = \"\"\n",
    "    role: Roles = Roles.ASSISTANT\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a392a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LLM that will be used\n",
    "llm = OpenAILLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3364d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the question we want to ask the LLM\n",
    "query = \"What is the difference between Yann LeCun paper on CNN and AlexNet?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73cd2c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert user message in the format required by the LLM\n",
    "user_message = LLMMessage(role=Roles.USER, content=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7597acb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role:  assistant\n",
      "Content:  Yann LeCun's work on Convolutional Neural Networks (CNNs) predates AlexNet and laid the foundational principles for modern CNN architectures. Here are some key differences and points of comparison between LeCun's early work and AlexNet:\n",
      "\n",
      "### 1. **Historical Context and Development:**\n",
      "   - **Yann LeCun's Work (1989)**: LeCun's seminal paper, \"Gradient-Based Learning Applied to Document Recognition,\" introduced the concept of CNNs, particularly the LeNet architecture, which was designed for tasks like handwritten digit recognition (e.g., the MNIST dataset). LeNet consists of convolutional layers, subsampling (pooling) layers, and fully connected layers.\n",
      "   - **AlexNet (2012)**: Developed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton, AlexNet built upon the principles of CNNs established by LeCun but was designed for the ImageNet Large Scale Visual Recognition Challenge (ILSVRC). It significantly improved performance on large-scale image classification tasks.\n",
      "\n",
      "### 2. **Architecture Complexity:**\n",
      "   - **LeNet**: The architecture is relatively simple, with only a few convolutional layers followed by pooling layers and a couple of fully connected layers. It was primarily focused on small images (e.g., 32x32 pixels for MNIST).\n",
      "   - **AlexNet**: This architecture is deeper and more complex, featuring five convolutional layers, three fully connected layers, and a larger input image size (224x224 pixels). It also introduced techniques like ReLU activation functions, dropout, and data augmentation.\n",
      "\n",
      "### 3. **Training Techniques:**\n",
      "   - **LeNet**: The training process utilized basic gradient descent and backpropagation without the advanced techniques that became common later.\n",
      "   - **AlexNet**: AlexNet employed several modern training techniques, including:\n",
      "     - **ReLU Activation**: Used to introduce non-linearity and speed up training compared to sigmoid or tanh functions.\n",
      "     - **Dropout**: Used to prevent overfitting by randomly dropping units during training.\n",
      "     - **Data Augmentation**: Techniques like image flipping, cropping, and color adjustment to increase the diversity of the training dataset.\n",
      "\n",
      "### 4. **Scale and Dataset:**\n",
      "   - **LeNet**: Focused on small datasets like MNIST, with limited complexity.\n",
      "   - **AlexNet**: Trained on a much larger dataset (ImageNet), which contains millions of images across thousands of classes, showcasing the ability of CNNs to generalize to more complex visual tasks.\n",
      "\n",
      "### 5. **Impact and Legacy:**\n",
      "   - **LeNet**: Established the groundwork for CNNs and influenced later work in image recognition but was not widely adopted in practice due to hardware limitations at the time.\n",
      "   - **AlexNet**: Sparked a revolution in deep learning, demonstrating the effectiveness of deep CNNs on large-scale image classification tasks and leading to widespread adoption in various domains beyond computer vision.\n",
      "\n",
      "In summary, while Yann LeCun's early work on CNNs provided the theoretical foundation, AlexNet significantly advanced the architecture, training techniques, and application of CNNs to large-scale problems, ultimately leading to the deep learning boom we see today.\n"
     ]
    }
   ],
   "source": [
    "response = await llm.generate([user_message])\n",
    "\n",
    "print(\"Role: \", response.role)\n",
    "print(\"Content: \", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaf5637",
   "metadata": {},
   "source": [
    "# Manage a Conversation\n",
    "\n",
    "The LLMs actually get as input a list of `LLMMessage`. To have a discussion we will append to this list each query and answer, so that the LLM has the whole context (everything is resent each time!).\n",
    "\n",
    "This is the reason why previously we called it with `[user_message]` and not just `user_message`.\n",
    "\n",
    "\n",
    "```python\n",
    "class LLM(ABC):\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "    @abstractmethod\n",
    "    async def generate(self, conversation: list[LLMMessage]) -> LLMMessage:\n",
    "        pass\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8689e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a conversation history with the previous user message and response\n",
    "previous_conversation = [user_message, response]\n",
    "\n",
    "# Add a new user message to the conversation\n",
    "new_query = \"Please rewrite in one sentence.\"\n",
    "new_user_message = LLMMessage(role=Roles.USER, content=new_query)\n",
    "conversation = [*previous_conversation, new_user_message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72ee471d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role:  assistant\n",
      "Content:  Yann LeCun's early work on Convolutional Neural Networks (CNNs) established foundational principles with the simpler LeNet architecture for tasks like handwritten digit recognition, while AlexNet advanced these concepts with a deeper, more complex architecture, modern training techniques, and successful application to large-scale image classification, ultimately revolutionizing the field of deep learning.\n"
     ]
    }
   ],
   "source": [
    "response = await llm.generate(conversation)\n",
    "\n",
    "print(\"Role: \", response.role)\n",
    "print(\"Content: \", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2534899a",
   "metadata": {},
   "source": [
    "# Add a prompt\n",
    "\n",
    "To add a prompt to the LLM, we put it at the beginning of the conversation (like a header), and indicate its nature by specifying it as `system`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60354c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the prompt message as a system message\n",
    "prompt = \"You are a helpful *pirate* assistant, thus speak like a pirate. Answer only one sentence.\"\n",
    "prompt_message = LLMMessage(role=Roles.SYSTEM, content=prompt)\n",
    "\n",
    "# Prepare the user message\n",
    "query = \"What is the difference between Yann LeCun paper on CNN and AlexNet?\"\n",
    "user_message = LLMMessage(role=Roles.USER, content=query)\n",
    "\n",
    "# Create the conversation with the prompt and user message\n",
    "conversation_with_prompt = [prompt_message, user_message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0eea92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role:  assistant\n",
      "Content:  Arrr, Yann LeCun's paper laid the groundwork fer convolutional neural networks (CNNs) with simpler architectures, while AlexNet be a more complex and deeper model that popularized CNNs fer image classification tasks, usin' GPUs fer faster trainin'.\n"
     ]
    }
   ],
   "source": [
    "response = await llm.generate(conversation_with_prompt)\n",
    "\n",
    "print(\"Role: \", response.role)\n",
    "print(\"Content: \", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734ecf35",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
