{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91350f1f",
   "metadata": {},
   "source": [
    "# 1.c LLM with tools\n",
    "\n",
    "In this notebook you will see:\n",
    "- How to create a tool\n",
    "- How to enable an LLM to use it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1828dc6",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "806535f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import Any\n",
    "import json\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "from conversational_toolkit.llms.base import LLMMessage, Roles\n",
    "from conversational_toolkit.tools.base import Tool\n",
    "from conversational_toolkit.llms.openai import OpenAILLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f1aeef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove logging\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"ERROR\", filter=lambda record: record[\"level\"].no < 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a50b800",
   "metadata": {},
   "source": [
    "# Define a tool\n",
    "\n",
    "The first step is to create a tool that the LLM will be able to use.\n",
    "\n",
    "For each tool, one has to implement it's core logic, but also explain what it does, plus specify it's input architecture. So that the LLM understands what is the tool for, and how to use it.\n",
    "\n",
    "Hint: It's important to raise errors as it might help the LLM to call themselves.\n",
    "\n",
    "\n",
    "```python\n",
    "class FunctionDescription(TypedDict):\n",
    "    name: str\n",
    "    description: str\n",
    "    parameters: dict[str, Any]\n",
    "\n",
    "\n",
    "class ToolDescription(TypedDict):\n",
    "    type: Literal[\"function\"]\n",
    "    function: FunctionDescription\n",
    "\n",
    "\n",
    "class Tool(ABC):\n",
    "    name: str\n",
    "    description: str\n",
    "    parameters: dict[str, Any]\n",
    "\n",
    "    @abstractmethod\n",
    "    async def call(self, args: dict[str, Any]) -> dict[str, Any]:\n",
    "        pass\n",
    "\n",
    "    def json_schema(self) -> ToolDescription:\n",
    "        return {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": self.name,\n",
    "                \"description\": self.description,\n",
    "                \"parameters\": self.parameters,\n",
    "            },\n",
    "        }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d837bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom tool that sums two numbers, it inherits from Tool\n",
    "class SumTwoNumbers(Tool):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        description: str,\n",
    "        parameters: dict[str, Any],\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.parameters = parameters\n",
    "\n",
    "    # Define the logic of the tool, specify the type hints\n",
    "    async def call(self, args: dict[str, Any]) -> dict[str, Any]:\n",
    "        number_1 = args.get(\"number_1\")\n",
    "        number_2 = args.get(\"number_2\")\n",
    "\n",
    "        if not isinstance(number_1, (int, float)) or not isinstance(\n",
    "            number_2, (int, float)\n",
    "        ):\n",
    "            raise ValueError(\"Both number_1 and number_2 must be int or float.\")\n",
    "\n",
    "        result = number_1 + number_2\n",
    "\n",
    "        return {\"result\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82d2f006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result': 15}\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the tool with appropriate metadata to describe its functionality\n",
    "tool_sum = SumTwoNumbers(\n",
    "    # Name, how it can be called\n",
    "    name=\"sum_two_numbers\",\n",
    "    # What it does\n",
    "    description=\"A tool to sum two numbers. It takes two numbers as input and returns their sum.\",\n",
    "    # What parameters it expects\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            # The first parameter\n",
    "            \"number_1\": {\n",
    "                # Type of the parameter\n",
    "                \"type\": \"number\",\n",
    "                # Description of the parameter\n",
    "                \"description\": \"The first number to be summed.\",\n",
    "            },\n",
    "            # The second parameter\n",
    "            \"number_2\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"The second number to be summed.\",\n",
    "            },\n",
    "        },\n",
    "        # Which parameters are required\n",
    "        \"required\": [\"number_1\", \"number_2\"],\n",
    "        # No additional properties allowed\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(await tool_sum.call({\"number_1\": 5, \"number_2\": 10}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c95bb1",
   "metadata": {},
   "source": [
    "# LLM using a tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a53397e",
   "metadata": {},
   "source": [
    "## Connect LLM to Tool\n",
    "\n",
    "Once the tool defined in a format understandable for the LLM, and that can be used to constraint it's usage, it can be provided to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4162d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role:  assistant\n",
      "Content:  \n",
      "Tool Calls:\n",
      "-  id='call_XjioLCbUbflOkoOY9eQB0OPH' function=Function(name='sum_two_numbers', arguments='{\"number_1\":15,\"number_2\":27}') type='function'\n"
     ]
    }
   ],
   "source": [
    "query = \"Sum the numbers 15 and 27 for me.\"\n",
    "user_message = LLMMessage(role=Roles.USER, content=query)\n",
    "\n",
    "# Define the LLM, but this time with the tool included\n",
    "# \"auto\" tool choice lets the LLM decide when to use the tool (not just always use it)\n",
    "llm = OpenAILLM(tools=[tool_sum], tool_choice=\"auto\")\n",
    "\n",
    "response = await llm.generate([user_message])\n",
    "\n",
    "print(\"Role: \", response.role)\n",
    "print(\"Content: \", response.content)\n",
    "print(\"Tool Calls:\")\n",
    "for tool_call in response.tool_calls:\n",
    "    print(\"- \", tool_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1635c6",
   "metadata": {},
   "source": [
    "## Run the Required Tools\n",
    "\n",
    "Now that the LLM is able to ask to call the tool, we have to run the tools. \n",
    "\n",
    "Note: This step will typically be hidden by the next wrappers we will implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84cb4f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result from tool 'sum_two_numbers': {'result': 42}\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "# For each tool the LLM asks for\n",
    "for tool_call in response.tool_calls:\n",
    "    tool_name = tool_call.function.name\n",
    "    tool_args = tool_call.function.arguments\n",
    "\n",
    "    # Find the tool by name\n",
    "    tool = next((t for t in llm.tools if t.name == tool_name), None)\n",
    "\n",
    "    # If the tool is found, call it with the provided arguments\n",
    "    if tool is not None:\n",
    "        tools_args_json = json.loads(tool_args)\n",
    "        tool_result = await tool.call(tools_args_json)\n",
    "\n",
    "        # Save the result of the tool call\n",
    "        results[tool_name] = tool_result\n",
    "\n",
    "for tool_name, result in results.items():\n",
    "    print(f\"Result from tool '{tool_name}': {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635bdb47",
   "metadata": {},
   "source": [
    "## Inform the LLM of the outcome\n",
    "\n",
    "Finally the LLM can get back the outcome of the prediction. We are simply sending back text to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5641c76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_answers = []\n",
    "\n",
    "# For each tool result, create a LLMMessage to pass back to the LLM\n",
    "for tool_call in response.tool_calls:\n",
    "    tool_name = tool_call.function.name\n",
    "    result = results[tool_name]\n",
    "    call_id = tool_call.id\n",
    "\n",
    "    tool_answer = LLMMessage(\n",
    "        role=Roles.TOOL,\n",
    "        name=tool_name,\n",
    "        content=json.dumps(result),\n",
    "        tool_call_id=call_id,\n",
    "    )\n",
    "    tools_answers.append(tool_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0bd4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the full conversation, including user message, LLM response, and tool answers\n",
    "conversation = [user_message, response, *tools_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "457f9590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role:  assistant\n",
      "Content:  The sum of 15 and 27 is 42.\n"
     ]
    }
   ],
   "source": [
    "# The LLM can now generate a final response based on the conversation\n",
    "# Which includes the tool results\n",
    "final_response = await llm.generate(conversation)\n",
    "\n",
    "print(\"Role: \", final_response.role)\n",
    "print(\"Content: \", final_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734ecf35",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
